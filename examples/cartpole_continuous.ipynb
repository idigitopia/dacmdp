{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1f82e61-12f2-4a6e-92e1-cf91c8e63776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc8efecc-4723-4df4-bbf5-b7e6ce882f2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aayam/miniconda3/envs/dacmdp/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gym\n",
    "import dacmdp\n",
    "import dacmdp.envs as ce\n",
    "# import wandb as wandb_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07ba47a7-8163-42f3-814e-6b8ca6cc07ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from munch import munchify \n",
    "\n",
    "config = munchify({\n",
    "\"envArgs\":{'env_name': 'CartPole-cont-v1', 'seed': 0},\n",
    "\"logArgs\":{'wandb_id': \"cartpole_online_test_1\", \"wandb_entity\":\"dacmdp\",\n",
    "           \"wandb_project\":\"dacmdp_online_test_v0\", \"no_wandb_logging\":True},\n",
    "\"dataArgs\": {'buffer_name': 'random', 'buffer_size': 25000, \n",
    "             'load_buffer': False, 'buffer_device': 'gpu', \"data_dir\":\"\"},\n",
    "\"reprModelArgs\": {'repr_model_name': 'OracleDynamicsRepr', 's_multiplyer': 1, 'a_multiplyer': 10, 'repr_dim': 4},\n",
    "\"actionModelArgs\": {'action_model_name': 'NNActionModelCuda', 'nn_engine': \"torch_pykeops\"},\n",
    "\"mdpBuildArgs\": {'n_tran_types': 10, 'n_tran_targets': 5, 'penalty_beta': 1.0, 'penalty_type': 'linear', 'rebuild_mdpfcache': False,\n",
    "                 'save_mdp2cache': False, 'save_folder': '/nfs/hpc/share/shrestaa/storage/dac_storage_22_Q4/mdp_dumps/random_hash'},\n",
    "\"mdpSolveArgs\": {'device': 'cuda', 'max_n_backups': 5000, \"gamma\": 0.99, 'epsilon': 0.0001, 'penalty_beta': 1, \"operator\": \"simple_backup\"},\n",
    "\"evalArgs\": {'eval_episode_count': 50, \"skip_eval\":True, \"skip_dist_log\":True},\n",
    "})\n",
    "\n",
    "flat_args = lambda config : {f\"{K}::{k}\":v for K in config for k,v in config[K].items() if K != \"flat_args\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ddcf975-7c0f-43d0-88dd-91ba7602c957",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Munch({'wandb_id': 'cartpole_online_test_1', 'wandb_entity': 'dacmdp', 'wandb_project': 'dacmdp_online_test_v0', 'no_wandb_logging': True})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.logArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9847177a-2d23-4da5-a65d-6d8d771f0046",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not config.logArgs.no_wandb_logging:\n",
    "    wandb_logger.init( id = config.logArgs.wandb_id ,\n",
    "        entity=config.logArgs.wandb_entity,\n",
    "        project=config.logArgs.wandb_project,\n",
    "        config = flat_args(config),\n",
    "        resume = \"allow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9d33a45-5551-4247-bf51-d843a8cb5f44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = gym.make(config.envArgs.env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8febdd77-0af2-4583-8a6c-2f6100656d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting buffer!\n",
      "Average Reward of collected trajectories:17.205\n",
      "Collected buffer!\n",
      "K-means for the Euclidean metric with 25,016 points in dimension 1, K = 10:\n",
      "Timing for 50 iterations: 0.03100s = 50 x 0.00062s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dacmdp.core.models_action import NNActionModel, GlobalClusterActionModel, EnsembleActionModel\n",
    "from dacmdp.core.models_sa_repr import OracleDynamicsRepr, DeltaPredictonRepr\n",
    "\n",
    "######### Get Action and Repr Models ####################################\n",
    "seed_buffer = dacmdp.utils_buffer.generate_or_load_buffer(config, env)\n",
    "cluster_action_count = 10\n",
    "cluster_action_model = GlobalClusterActionModel(action_space=env.action_space,\n",
    "                                   n_actions= cluster_action_count,\n",
    "                                   data_buffer=seed_buffer)\n",
    "\n",
    "sa_repr_model = OracleDynamicsRepr(env_name = config.envArgs.env_name)\n",
    "\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2de04272-913f-4403-be3e-d49e84d1f87a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import d4rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc7366ef-c7b8-48c7-8c5c-a974d404d442",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4978],\n",
       "         [ 0.4955],\n",
       "         [ 0.9016],\n",
       "         [-0.0936],\n",
       "         [ 0.2956],\n",
       "         [-0.6976],\n",
       "         [-0.2966],\n",
       "         [ 0.1011],\n",
       "         [-0.9001],\n",
       "         [ 0.6990]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_action_model.cand_actions_for_states(torch.FloatTensor(seed_buffer.state[0:1]).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c516c3-e1dc-4487-b7fd-91c4823ae2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "421352ce-5219-4ee4-a728-8523caf9e491",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aayam/Documents/workspaces/dacmdp/dacmdp/envs/cont_cartpole.py:108: UserWarning: \u001b[33mWARN: \n",
      "You are calling 'step()' even though this environment has already returned\n",
      "done = True. You should always call 'reset()' once you receive 'done = True'\n",
      "Any further steps are undnp.float32(low), np.float32(high)efined behavior.\n",
      "                \u001b[0m\n",
      "  \"\"\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 10, 1]), torch.Size([100, 4]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_action_model.cand_actions_for_states(torch.FloatTensor(seed_buffer.state[0:100]).cuda()).shape,\\\n",
    "sa_repr_model.encode_state_action_pairs(torch.FloatTensor(seed_buffer.state[0:100]),\n",
    "                                       torch.FloatTensor(seed_buffer.action[0:100])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e057ed19-87e6-4ca0-8533-44bfafab44f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dacmdp.data.utils_buffer import StandardElasticBuffer\n",
    "global_buffer = StandardElasticBuffer(state_shape = env.observation_space.shape,\n",
    "               action_shape = [len(env.action_space.sample())], # for discrete settings. \n",
    "                batch_size=32, buffer_size=100000, device=\"cpu\")\n",
    "# policy liftup functions\n",
    "def dummy_lifted_policy(Agent, s, epsilon):\n",
    "    if torch.rand(1).item() < epsilon:\n",
    "        return env.action_space.sample()\n",
    "    else:\n",
    "        nn_s_idx =  THelper.calc_knn_indices(torch.FloatTensor(s).to(Agent.device), Agent.dacmdp_core.S, 1)[0]\n",
    "        policy_idx = Agent.dacmdp_core.Pi[nn_s_idx] \n",
    "        return Agent.A_names[nn_s_idx,policy_idx].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c524f0e-079d-48ee-8768-606df90c3da2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config.evalArgs.skip_eval = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4057745-881a-4705-930f-c1391ef79243",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dacmdp_core_defined\n",
      "Using pre-initialized Action Model GlobalClusterActionModel\n",
      "Using pre-initialized Action Model <dacmdp.core.models_sa_repr.DeltaPredictonRepr object at 0x7f55d6d3f490>\n",
      "Average Reward of collected trajectories:18.6\n",
      "Average Reward of collected trajectories:14.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 41it [00:00, 31363.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(10000, 15, 5)\n",
      "nn after consumption,  10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 408.52it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 360.47it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 276.66it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 198.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(1.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 tensor(0.0066)\n",
      "1000 tensor(6.8665e-05)\n",
      "Solved MDP in 1000 Backups\n",
      "Epoch 0: Graph built and solved in 0.28 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 14.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Evaluation compltete 260.71 Time:  6.692664623260498 Seconds\n",
      "Average Reward of collected trajectories:204.7\n",
      "Average Reward of collected trajectories:235.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 58it [00:00, 56931.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(20000, 15, 5)\n",
      "nn after consumption,  20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 356.65it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 332.19it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 274.30it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 171.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.7774)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 tensor(0.0003)\n",
      "1000 tensor(1.5259e-05)\n",
      "Solved MDP in 1000 Backups\n",
      "Epoch 1: Graph built and solved in 0.31 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:11<00:00,  8.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Evaluation compltete 392.17 Time:  11.249489307403564 Seconds\n",
      "Average Reward of collected trajectories:274.6\n",
      "Average Reward of collected trajectories:419.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 85it [00:00, 58550.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(30000, 15, 5)\n",
      "nn after consumption,  30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 317.26it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 311.36it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 250.45it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 162.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9915)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 tensor(0.0003)\n",
      "1000 tensor(7.6294e-06)\n",
      "Solved MDP in 1000 Backups\n",
      "Epoch 2: Graph built and solved in 0.37 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:11<00:00,  8.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Evaluation compltete 399.36 Time:  11.427972316741943 Seconds\n",
      "Average Reward of collected trajectories:207.4\n",
      "Average Reward of collected trajectories:448.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 111it [00:00, 47386.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(40000, 15, 5)\n",
      "nn after consumption,  40000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 258.07it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 289.98it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 238.27it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 142.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9945)\n",
      "500 tensor(0.0001)\n",
      "1000 tensor(0.)\n",
      "Solved MDP in 1000 Backups\n",
      "Epoch 3: Graph built and solved in 0.43 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Evaluation compltete 430.82 Time:  12.697758913040161 Seconds\n",
      "Average Reward of collected trajectories:260.6\n",
      "Average Reward of collected trajectories:398.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 137it [00:00, 68163.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(50000, 15, 5)\n",
      "nn after consumption,  50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 214.89it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 245.47it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 195.33it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 116.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9967)\n",
      "500 tensor(0.0007)\n",
      "1000 tensor(7.6294e-06)\n",
      "Solved MDP in 1000 Backups\n",
      "Epoch 4: Graph built and solved in 0.52 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Evaluation compltete 428.8 Time:  12.840603828430176 Seconds\n",
      "Average Reward of collected trajectories:225.5\n",
      "Average Reward of collected trajectories:447.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 163it [00:00, 83486.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(60000, 15, 5)\n",
      "nn after consumption,  60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 195.13it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 222.55it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 183.44it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 108.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9960)\n",
      "500 tensor(0.0004)\n",
      "1000 tensor(7.6294e-06)\n",
      "Solved MDP in 1000 Backups\n",
      "Epoch 5: Graph built and solved in 0.59 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:13<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Evaluation compltete 454.31 Time:  13.294954776763916 Seconds\n",
      "Average Reward of collected trajectories:264.5\n",
      "Average Reward of collected trajectories:447.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 191it [00:00, 100151.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(70000, 15, 5)\n",
      "nn after consumption,  70000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 175.76it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 200.99it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 170.55it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 112.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9971)\n",
      "500 tensor(0.0001)\n",
      "1000 tensor(0.)\n",
      "Solved MDP in 1000 Backups\n",
      "Epoch 6: Graph built and solved in 0.64 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Evaluation compltete 431.78 Time:  12.69064211845398 Seconds\n",
      "Average Reward of collected trajectories:181.9\n",
      "Average Reward of collected trajectories:477.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 216it [00:00, 87255.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(80000, 15, 5)\n",
      "nn after consumption,  80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 158.30it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 192.85it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 153.63it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 90.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9970)\n",
      "500 tensor(8.3923e-05)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 7: Graph built and solved in 0.52 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Evaluation compltete 436.94 Time:  12.903290271759033 Seconds\n",
      "Average Reward of collected trajectories:222.2\n",
      "Average Reward of collected trajectories:425.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 242it [00:00, 118841.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(90000, 15, 5)\n",
      "nn after consumption,  90000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 147.64it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 180.62it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 145.96it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 105.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9977)\n",
      "500 tensor(0.0025)\n",
      "1000 tensor(1.5259e-05)\n",
      "Solved MDP in 1000 Backups\n",
      "Epoch 8: Graph built and solved in 0.77 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Evaluation compltete 430.16 Time:  12.567831039428711 Seconds\n",
      "Average Reward of collected trajectories:209.8\n",
      "Average Reward of collected trajectories:468.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 268it [00:00, 174274.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(100000, 15, 5)\n",
      "nn after consumption,  100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 141.61it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 176.92it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 156.65it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 104.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9979)\n",
      "500 tensor(0.)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 9: Graph built and solved in 0.57 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:13<00:00,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Evaluation compltete 461.05 Time:  13.427865982055664 Seconds\n",
      "Average Reward of collected trajectories:217.7\n",
      "Average Reward of collected trajectories:474.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 295it [00:00, 145327.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(110000, 15, 5)\n",
      "nn after consumption,  110000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 133.08it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 157.93it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 131.56it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 96.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9974)\n",
      "500 tensor(0.0060)\n",
      "1000 tensor(3.8147e-05)\n",
      "Solved MDP in 1000 Backups\n",
      "Epoch 10: Graph built and solved in 0.90 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Evaluation compltete 429.0 Time:  12.766106367111206 Seconds\n",
      "Average Reward of collected trajectories:259.6\n",
      "Average Reward of collected trajectories:427.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 322it [00:00, 140830.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(120000, 15, 5)\n",
      "nn after consumption,  120000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 119.45it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 155.95it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 160.29it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 85.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9982)\n",
      "500 tensor(0.)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 11: Graph built and solved in 0.66 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:13<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Evaluation compltete 446.23 Time:  13.29692029953003 Seconds\n",
      "Average Reward of collected trajectories:267.6\n",
      "Average Reward of collected trajectories:433.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 349it [00:00, 142518.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(130000, 15, 5)\n",
      "nn after consumption,  130000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 114.83it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 142.06it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 115.94it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 80.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9978)\n",
      "500 tensor(0.)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 12: Graph built and solved in 0.73 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Evaluation compltete 442.79 Time:  12.875975370407104 Seconds\n",
      "Average Reward of collected trajectories:188.4\n",
      "Average Reward of collected trajectories:477.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 375it [00:00, 118331.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(140000, 15, 5)\n",
      "nn after consumption,  140000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 108.56it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 142.30it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 118.84it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 76.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9972)\n",
      "500 tensor(0.0002)\n",
      "1000 tensor(0.)\n",
      "Solved MDP in 1000 Backups\n",
      "Epoch 13: Graph built and solved in 1.11 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  7.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Evaluation compltete 427.74 Time:  12.585324048995972 Seconds\n",
      "Average Reward of collected trajectories:238.9\n",
      "Average Reward of collected trajectories:461.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 403it [00:00, 115111.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(150000, 15, 5)\n",
      "nn after consumption,  150000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 102.19it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 135.66it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 105.94it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 71.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9977)\n",
      "500 tensor(0.0003)\n",
      "1000 tensor(0.)\n",
      "Solved MDP in 1000 Backups\n",
      "Epoch 14: Graph built and solved in 1.18 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:13<00:00,  7.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Evaluation compltete 448.22 Time:  13.103813886642456 Seconds\n",
      "Average Reward of collected trajectories:147.6\n",
      "Average Reward of collected trajectories:448.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 426it [00:00, 138081.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(160000, 15, 5)\n",
      "nn after consumption,  160000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 97.63it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 127.66it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 110.73it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 73.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9984)\n",
      "500 tensor(0.)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 15: Graph built and solved in 0.83 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:13<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Evaluation compltete 462.73 Time:  13.656243324279785 Seconds\n",
      "Average Reward of collected trajectories:223.6\n",
      "Average Reward of collected trajectories:491.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 454it [00:00, 147923.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(170000, 15, 5)\n",
      "nn after consumption,  170000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 91.86it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 119.61it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 107.96it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 67.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9981)\n",
      "500 tensor(7.6294e-05)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 16: Graph built and solved in 0.89 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:13<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Evaluation compltete 471.0 Time:  13.614338397979736 Seconds\n",
      "Average Reward of collected trajectories:231.4\n",
      "Average Reward of collected trajectories:449.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 481it [00:00, 181328.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(180000, 15, 5)\n",
      "nn after consumption,  180000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 87.01it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 125.43it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 125.00it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 66.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9984)\n",
      "500 tensor(3.0518e-05)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 17: Graph built and solved in 0.90 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:13<00:00,  7.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Evaluation compltete 456.4 Time:  13.241358280181885 Seconds\n",
      "Average Reward of collected trajectories:251.2\n",
      "Average Reward of collected trajectories:464.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 509it [00:00, 187354.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(190000, 15, 5)\n",
      "nn after consumption,  190000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 82.94it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 111.32it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 97.94it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 62.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9980)\n",
      "500 tensor(0.)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 18: Graph built and solved in 0.98 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:13<00:00,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Evaluation compltete 457.79 Time:  13.42880892753601 Seconds\n",
      "Average Reward of collected trajectories:184.0\n",
      "Average Reward of collected trajectories:500.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 535it [00:00, 165997.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(200000, 15, 5)\n",
      "nn after consumption,  200000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 78.81it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 131.56it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 112.31it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 61.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9972)\n",
      "500 tensor(6.8665e-05)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 19: Graph built and solved in 0.98 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Evaluation compltete 445.66 Time:  12.814159870147705 Seconds\n",
      "Average Reward of collected trajectories:263.9\n",
      "Average Reward of collected trajectories:478.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 564it [00:00, 113430.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(210000, 15, 5)\n",
      "nn after consumption,  210000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 74.66it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 121.02it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 106.00it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 59.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9979)\n",
      "500 tensor(0.)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 20: Graph built and solved in 1.03 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:13<00:00,  7.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Evaluation compltete 457.43 Time:  13.25455355644226 Seconds\n",
      "Average Reward of collected trajectories:298.7\n",
      "Average Reward of collected trajectories:437.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 593it [00:00, 142379.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(220000, 15, 5)\n",
      "nn after consumption,  220000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 73.75it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 128.26it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 105.36it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 58.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9980)\n",
      "500 tensor(6.8665e-05)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 21: Graph built and solved in 1.05 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Evaluation compltete 445.77 Time:  12.865071535110474 Seconds\n",
      "Average Reward of collected trajectories:170.5\n",
      "Average Reward of collected trajectories:448.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 617it [00:00, 6395.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(230000, 15, 5)\n",
      "nn after consumption,  230000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 68.91it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 111.10it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 97.06it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 56.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9973)\n",
      "500 tensor(1.5259e-05)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 22: Graph built and solved in 1.11 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Evaluation compltete 442.48 Time:  12.680509328842163 Seconds\n",
      "Average Reward of collected trajectories:190.0\n",
      "Average Reward of collected trajectories:489.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 644it [00:00, 218821.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(240000, 15, 5)\n",
      "nn after consumption,  240000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 61.11it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 91.37it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 95.06it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 52.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9971)\n",
      "500 tensor(2.2888e-05)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 23: Graph built and solved in 1.20 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:13<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Evaluation compltete 462.59 Time:  13.266698360443115 Seconds\n",
      "Average Reward of collected trajectories:132.6\n",
      "Average Reward of collected trajectories:446.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 666it [00:00, 150175.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(250000, 15, 5)\n",
      "nn after consumption,  250000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 63.71it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 87.06it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 93.16it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 52.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9984)\n",
      "500 tensor(0.)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 24: Graph built and solved in 1.22 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Evaluation compltete 452.46 Time:  12.82999587059021 Seconds\n",
      "Average Reward of collected trajectories:195.8\n",
      "Average Reward of collected trajectories:456.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 692it [00:00, 143942.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(260000, 15, 5)\n",
      "nn after consumption,  260000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 63.19it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 113.51it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 90.78it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 50.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9984)\n",
      "500 tensor(0.)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 25: Graph built and solved in 1.23 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:13<00:00,  7.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Evaluation compltete 467.16 Time:  13.505635738372803 Seconds\n",
      "Average Reward of collected trajectories:187.0\n",
      "Average Reward of collected trajectories:430.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 716it [00:00, 173090.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(270000, 15, 5)\n",
      "nn after consumption,  270000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 60.09it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 107.89it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 91.71it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 48.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9972)\n",
      "500 tensor(0.0014)\n",
      "1000 tensor(7.6294e-06)\n",
      "Solved MDP in 1000 Backups\n",
      "Epoch 26: Graph built and solved in 1.94 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:13<00:00,  7.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Evaluation compltete 458.56 Time:  13.150527238845825 Seconds\n",
      "Average Reward of collected trajectories:233.6\n",
      "Average Reward of collected trajectories:497.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 744it [00:00, 227562.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(280000, 15, 5)\n",
      "nn after consumption,  280000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 63.13it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 106.06it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 86.01it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 47.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9972)\n",
      "500 tensor(4.5776e-05)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 27: Graph built and solved in 1.31 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:13<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Evaluation compltete 457.95 Time:  13.724427938461304 Seconds\n",
      "Average Reward of collected trajectories:241.7\n",
      "Average Reward of collected trajectories:466.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 772it [00:00, 237896.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(290000, 15, 5)\n",
      "nn after consumption,  290000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 60.13it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 102.11it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 83.16it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 45.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9985)\n",
      "500 tensor(6.8665e-05)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 28: Graph built and solved in 1.35 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:13<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Evaluation compltete 455.97 Time:  13.602405786514282 Seconds\n",
      "Average Reward of collected trajectories:244.0\n",
      "Average Reward of collected trajectories:444.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 799it [00:00, 146483.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(300000, 15, 5)\n",
      "nn after consumption,  300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 54.70it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 90.69it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 81.80it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 44.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9989)\n",
      "500 tensor(0.0002)\n",
      "1000 tensor(0.)\n",
      "Solved MDP in 1000 Backups\n",
      "Epoch 29: Graph built and solved in 2.14 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:13<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Evaluation compltete 456.37 Time:  13.730581998825073 Seconds\n",
      "Average Reward of collected trajectories:270.4\n",
      "Average Reward of collected trajectories:405.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 825it [00:00, 231226.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(310000, 15, 5)\n",
      "nn after consumption,  310000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 54.47it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 98.30it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 77.89it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 42.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9986)\n",
      "500 tensor(7.6294e-05)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 30: Graph built and solved in 1.45 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:14<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Evaluation compltete 468.22 Time:  14.073994636535645 Seconds\n",
      "Average Reward of collected trajectories:216.0\n",
      "Average Reward of collected trajectories:498.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 853it [00:00, 220930.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(320000, 15, 5)\n",
      "nn after consumption,  320000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 54.62it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 79.95it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 77.87it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 43.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9983)\n",
      "500 tensor(0.)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 31: Graph built and solved in 1.49 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:14<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Evaluation compltete 458.42 Time:  14.080122947692871 Seconds\n",
      "Average Reward of collected trajectories:182.3\n",
      "Average Reward of collected trajectories:443.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 878it [00:00, 177860.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(330000, 15, 5)\n",
      "nn after consumption,  330000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 51.45it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 77.60it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 74.84it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 41.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9983)\n",
      "500 tensor(0.)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 32: Graph built and solved in 1.54 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:13<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Evaluation compltete 454.81 Time:  13.99935269355774 Seconds\n",
      "Average Reward of collected trajectories:274.0\n",
      "Average Reward of collected trajectories:476.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 907it [00:00, 170761.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(340000, 15, 5)\n",
      "nn after consumption,  340000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 54.72it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 84.44it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 71.74it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 40.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9983)\n",
      "500 tensor(0.)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 33: Graph built and solved in 1.56 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:14<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Evaluation compltete 455.9 Time:  14.035643815994263 Seconds\n",
      "Average Reward of collected trajectories:312.3\n",
      "Average Reward of collected trajectories:453.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 937it [00:00, 164734.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(350000, 15, 5)\n",
      "nn after consumption,  350000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 50.70it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 76.23it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 70.61it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 39.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9992)\n",
      "500 tensor(0.0001)\n",
      "1000 tensor(0.)\n",
      "Solved MDP in 1000 Backups\n",
      "Epoch 34: Graph built and solved in 2.47 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:14<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Evaluation compltete 468.73 Time:  14.546848773956299 Seconds\n",
      "Average Reward of collected trajectories:274.7\n",
      "Average Reward of collected trajectories:497.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 967it [00:00, 201535.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(360000, 15, 5)\n",
      "nn after consumption,  360000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 46.37it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 84.24it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 69.65it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 38.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9985)\n",
      "500 tensor(0.0001)\n",
      "1000 tensor(0.)\n",
      "Solved MDP in 1000 Backups\n",
      "Epoch 35: Graph built and solved in 2.53 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:14<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Evaluation compltete 463.41 Time:  14.411942720413208 Seconds\n",
      "Average Reward of collected trajectories:235.5\n",
      "Average Reward of collected trajectories:415.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 993it [00:00, 239860.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(370000, 15, 5)\n",
      "nn after consumption,  370000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 48.24it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 84.19it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 66.87it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 37.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9980)\n",
      "500 tensor(2.2888e-05)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 36: Graph built and solved in 1.69 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:14<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Evaluation compltete 469.8 Time:  14.658080577850342 Seconds\n",
      "Average Reward of collected trajectories:189.3\n",
      "Average Reward of collected trajectories:425.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 1017it [00:00, 243986.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(380000, 15, 5)\n",
      "nn after consumption,  380000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 45.08it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 72.75it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 65.90it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 36.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9984)\n",
      "500 tensor(0.)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 37: Graph built and solved in 1.76 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:14<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Evaluation compltete 456.09 Time:  14.32384967803955 Seconds\n",
      "Average Reward of collected trajectories:301.4\n",
      "Average Reward of collected trajectories:456.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 1046it [00:00, 262238.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(390000, 15, 5)\n",
      "nn after consumption,  390000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 42.79it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 80.95it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 64.05it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 35.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9989)\n",
      "500 tensor(0.)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 38: Graph built and solved in 1.79 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:14<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Evaluation compltete 465.62 Time:  14.493932008743286 Seconds\n",
      "Average Reward of collected trajectories:288.2\n",
      "Average Reward of collected trajectories:457.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 1075it [00:00, 184805.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(400000, 15, 5)\n",
      "nn after consumption,  400000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 47.33it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 74.22it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 63.61it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 34.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9987)\n",
      "500 tensor(0.)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 39: Graph built and solved in 1.81 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:14<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Evaluation compltete 452.26 Time:  14.25987195968628 Seconds\n",
      "Average Reward of collected trajectories:244.6\n",
      "Average Reward of collected trajectories:472.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 1103it [00:00, 158979.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(410000, 15, 5)\n",
      "nn after consumption,  410000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 41.15it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 75.92it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 62.07it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 34.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9980)\n",
      "500 tensor(0.)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 40: Graph built and solved in 1.87 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:14<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Evaluation compltete 454.36 Time:  14.544842958450317 Seconds\n",
      "Average Reward of collected trajectories:239.7\n",
      "Average Reward of collected trajectories:422.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 1129it [00:00, 249177.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(420000, 15, 5)\n",
      "nn after consumption,  420000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 46.68it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 74.76it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 61.97it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 33.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9990)\n",
      "500 tensor(0.)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 41: Graph built and solved in 1.87 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:14<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Evaluation compltete 451.73 Time:  14.30616545677185 Seconds\n",
      "Average Reward of collected trajectories:169.5\n",
      "Average Reward of collected trajectories:475.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 1154it [00:00, 259334.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(430000, 15, 5)\n",
      "nn after consumption,  430000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 38.95it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 71.51it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 60.11it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 33.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9984)\n",
      "500 tensor(6.8665e-05)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 42: Graph built and solved in 1.96 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:15<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Evaluation compltete 468.07 Time:  15.091080665588379 Seconds\n",
      "Average Reward of collected trajectories:261.9\n",
      "Average Reward of collected trajectories:482.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 1183it [00:00, 145692.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(440000, 15, 5)\n",
      "nn after consumption,  440000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 39.24it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 71.60it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 58.49it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 32.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9984)\n",
      "500 tensor(3.8147e-05)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 43: Graph built and solved in 2.00 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:15<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Evaluation compltete 460.43 Time:  15.032469511032104 Seconds\n",
      "Average Reward of collected trajectories:160.9\n",
      "Average Reward of collected trajectories:448.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 1207it [00:00, 167234.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(450000, 15, 5)\n",
      "nn after consumption,  450000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 39.31it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 70.17it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 58.01it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 31.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9987)\n",
      "500 tensor(6.8665e-05)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 44: Graph built and solved in 2.02 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:16<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Evaluation compltete 472.11 Time:  16.147308826446533 Seconds\n",
      "Average Reward of collected trajectories:154.0\n",
      "Average Reward of collected trajectories:444.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 1231it [00:00, 190312.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(460000, 15, 5)\n",
      "nn after consumption,  460000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 40.11it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 70.49it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 57.87it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 30.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9985)\n",
      "500 tensor(0.0002)\n",
      "1000 tensor(0.)\n",
      "Solved MDP in 1000 Backups\n",
      "Epoch 45: Graph built and solved in 3.28 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:15<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Evaluation compltete 451.76 Time:  15.447072744369507 Seconds\n",
      "Average Reward of collected trajectories:229.5\n",
      "Average Reward of collected trajectories:466.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 1258it [00:00, 199200.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(470000, 15, 5)\n",
      "nn after consumption,  470000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 44.04it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 70.22it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 57.07it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 29.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9976)\n",
      "500 tensor(0.)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 46: Graph built and solved in 2.12 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:15<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Evaluation compltete 459.47 Time:  15.535118103027344 Seconds\n",
      "Average Reward of collected trajectories:181.9\n",
      "Average Reward of collected trajectories:465.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 1283it [00:00, 206069.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(480000, 15, 5)\n",
      "nn after consumption,  480000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 41.15it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 67.44it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 54.30it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 29.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9980)\n",
      "500 tensor(3.8147e-05)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 47: Graph built and solved in 2.13 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:15<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Evaluation compltete 463.62 Time:  15.795887231826782 Seconds\n",
      "Average Reward of collected trajectories:222.0\n",
      "Average Reward of collected trajectories:478.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 1310it [00:00, 197922.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(490000, 15, 5)\n",
      "nn after consumption,  490000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 36.30it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 66.71it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 54.15it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 28.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9987)\n",
      "500 tensor(0.)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 48: Graph built and solved in 2.28 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:16<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Evaluation compltete 472.2 Time:  16.286128282546997 Seconds\n",
      "Average Reward of collected trajectories:281.2\n",
      "Average Reward of collected trajectories:465.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 1340it [00:00, 301829.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(500000, 15, 5)\n",
      "nn after consumption,  500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 37.21it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 63.71it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 52.88it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 27.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9985)\n",
      "500 tensor(2.2888e-05)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 49: Graph built and solved in 2.27 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:16<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Evaluation compltete 468.42 Time:  16.29965615272522 Seconds\n",
      "Average Reward of collected trajectories:246.7\n",
      "Average Reward of collected trajectories:418.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 1366it [00:00, 241696.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(510000, 15, 5)\n",
      "nn after consumption,  510000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 34.64it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 65.01it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 52.93it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 28.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9983)\n",
      "500 tensor(0.0001)\n",
      "1000 tensor(0.)\n",
      "Solved MDP in 1000 Backups\n",
      "Epoch 50: Graph built and solved in 3.62 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:16<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Evaluation compltete 459.03 Time:  16.302430629730225 Seconds\n",
      "Average Reward of collected trajectories:228.6\n",
      "Average Reward of collected trajectories:470.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 1393it [00:00, 149731.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(520000, 15, 5)\n",
      "nn after consumption,  520000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 33.90it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 63.84it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 51.77it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 28.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9990)\n",
      "500 tensor(0.0018)\n",
      "1000 tensor(7.6294e-06)\n",
      "Solved MDP in 1000 Backups\n",
      "Epoch 51: Graph built and solved in 3.63 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:16<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: Evaluation compltete 467.38 Time:  16.291253089904785 Seconds\n",
      "Average Reward of collected trajectories:271.4\n",
      "Average Reward of collected trajectories:481.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 1422it [00:00, 159785.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(530000, 15, 5)\n",
      "nn after consumption,  530000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 33.29it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 62.58it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 49.16it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 27.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9991)\n",
      "500 tensor(0.0002)\n",
      "1000 tensor(0.)\n",
      "Solved MDP in 1000 Backups\n",
      "Epoch 52: Graph built and solved in 3.85 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:15<00:00,  6.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: Evaluation compltete 450.27 Time:  15.74912405014038 Seconds\n",
      "Average Reward of collected trajectories:298.8\n",
      "Average Reward of collected trajectories:474.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 1453it [00:00, 279287.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(540000, 15, 5)\n",
      "nn after consumption,  540000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 34.18it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 57.95it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 48.54it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 25.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9981)\n",
      "500 tensor(0.)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 53: Graph built and solved in 2.43 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:15<00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: Evaluation compltete 464.66 Time:  15.896193742752075 Seconds\n",
      "Average Reward of collected trajectories:227.6\n",
      "Average Reward of collected trajectories:414.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 1478it [00:00, 281014.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(550000, 15, 5)\n",
      "nn after consumption,  550000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 37.87it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 60.80it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 49.01it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 26.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9983)\n",
      "500 tensor(0.0002)\n",
      "1000 tensor(7.6294e-06)\n",
      "Solved MDP in 1000 Backups\n",
      "Epoch 54: Graph built and solved in 3.79 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:15<00:00,  6.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: Evaluation compltete 450.15 Time:  15.692539930343628 Seconds\n",
      "Average Reward of collected trajectories:359.1\n",
      "Average Reward of collected trajectories:494.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 1511it [00:00, 152544.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(560000, 15, 5)\n",
      "nn after consumption,  560000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 35.95it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 57.77it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 47.94it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 26.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9989)\n",
      "500 tensor(0.0001)\n",
      "1000 tensor(7.6294e-06)\n",
      "Solved MDP in 1000 Backups\n",
      "Epoch 55: Graph built and solved in 3.93 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:17<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: Evaluation compltete 485.14 Time:  17.23331046104431 Seconds\n",
      "Average Reward of collected trajectories:245.0\n",
      "Average Reward of collected trajectories:458.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 1538it [00:00, 189307.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(570000, 15, 5)\n",
      "nn after consumption,  570000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 36.25it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 59.00it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 47.78it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 24.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9991)\n",
      "500 tensor(0.)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 56: Graph built and solved in 2.51 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:15<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: Evaluation compltete 450.53 Time:  15.508176565170288 Seconds\n",
      "Average Reward of collected trajectories:314.5\n",
      "Average Reward of collected trajectories:487.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 1570it [00:00, 283484.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(580000, 15, 5)\n",
      "nn after consumption,  580000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 33.32it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 57.97it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 46.57it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 25.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9985)\n",
      "500 tensor(4.5776e-05)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 57: Graph built and solved in 2.53 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:16<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Evaluation compltete 470.62 Time:  16.387381076812744 Seconds\n",
      "Average Reward of collected trajectories:273.7\n",
      "Average Reward of collected trajectories:471.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 1599it [00:00, 259637.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(590000, 15, 5)\n",
      "nn after consumption,  590000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 32.07it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 56.89it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 46.45it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 25.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9982)\n",
      "500 tensor(5.3406e-05)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 58: Graph built and solved in 2.64 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:15<00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Evaluation compltete 459.42 Time:  15.85727047920227 Seconds\n",
      "Average Reward of collected trajectories:271.3\n",
      "Average Reward of collected trajectories:487.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 1628it [00:00, 235078.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(600000, 15, 5)\n",
      "nn after consumption,  600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 34.57it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 53.40it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 41.94it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 22.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9981)\n",
      "500 tensor(0.)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 59: Graph built and solved in 2.78 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:16<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: Evaluation compltete 463.06 Time:  16.958012104034424 Seconds\n",
      "Average Reward of collected trajectories:204.7\n",
      "Average Reward of collected trajectories:415.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caculating State Representations: : 1653it [00:00, 146014.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_next_states.shape torch.Size([10000, 4])\n",
      "replace indices :  False torch.Size([10000, 4])\n",
      "Instantiated DACMDP for transition Batch\n",
      "(610000, 15, 5)\n",
      "nn after consumption,  610000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Candidate Actions: : 10it [00:00, 32.06it/s]\n",
      "Calculate/Update Datsaet SA Representation: : 10it [00:00, 52.49it/s]\n",
      "Calculate/Update Candidate Transition SA Representation: : 10it [00:00, 43.31it/s]\n",
      "Update Transition model of core dacmdp: : 10it [00:00, 23.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(99.9979)\n",
      "500 tensor(0.)\n",
      "Solved MDP in 500 Backups\n",
      "Epoch 60: Graph built and solved in 2.75 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████████████████████████████████▏                                                          | 44/100 [00:07<00:09,  6.02it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_77835/1484669779.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0meval_policy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdummy_lifted_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melasticAgent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevalArgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_episode_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mavg_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_on_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevalArgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_episode_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0meval_time\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch_i}: Evaluation compltete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Time: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/workspaces/dacmdp/dacmdp/eval/utils_eval.py\u001b[0m in \u001b[0;36mevaluate_on_env\u001b[0;34m(env, policy_func, eps_count, verbose, render, lag, progress_bar, episode_hook_fxn, before_step_hook_fxn, after_step_hook_fxn, action_repeat, eval_eps, render_mode, render_width, render_height)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# logic to not get stuck\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m# policyAction = policy_func(state_c) if np.random.uniform(0,1) > eval_eps else env.action_space.sample()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mpolicyAction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_77835/1484669779.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevalArgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0meval_policy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdummy_lifted_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melasticAgent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevalArgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_episode_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mavg_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_on_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevalArgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_episode_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_77835/1912965405.py\u001b[0m in \u001b[0;36mdummy_lifted_policy\u001b[0;34m(Agent, s, epsilon)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mnn_s_idx\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mTHelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_knn_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAgent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdacmdp_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mpolicy_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdacmdp_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnn_s_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnn_s_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpolicy_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/workspaces/dacmdp/dacmdp/core/utils_knn.py\u001b[0m in \u001b[0;36mcalc_knn_indices\u001b[0;34m(query, data, k)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalc_knn_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlargest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dacmdp/lib/python3.7/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m   1527\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1530\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "from dacmdp.core.utils_misc import plot_distributions_as_rgb_array\n",
    "from dacmdp.eval.utils_eval import evaluate_on_env\n",
    "from dacmdp.data.utils_buffer import StandardBuffer\n",
    "from dacmdp.core.dac_core import DACTransitionBatch\n",
    "from dacmdp.core.dac_build import DACBuildWithActionNames\n",
    "from dacmdp.core.utils_knn import THelper\n",
    "\n",
    "total_training_points = 200000\n",
    "point_batch_size = 10000\n",
    "curr_data_points = 0\n",
    "avg_rewards = 0\n",
    "rewards_log = []\n",
    "dac_plot_log = []\n",
    "images = 0\n",
    "\n",
    "# Instantiate Elastic Agent\n",
    "config.mdpBuildArgs.n_tran_types = cluster_action_count + 5\n",
    "elasticAgent = DACBuildWithActionNames( config = config, \n",
    "                                    action_space = env.action_space, \n",
    "                                    action_model = cluster_action_model, # Update this later.\n",
    "                                    repr_model = sa_repr_model, \n",
    "                                    effective_batch_size= 1000, \n",
    "                                    batch_calc_knn_ret_flat_engine = THelper.batch_calc_knn_ret_flat_pykeops\n",
    "                                    )\n",
    "\n",
    "for epoch_i in range(100):\n",
    "    ######### TT 1: Data collect   ###########################################################################\n",
    "    random_policy = lambda s:dummy_lifted_policy(elasticAgent,s, epsilon = 1)\n",
    "    explore_policy = lambda s:dummy_lifted_policy(elasticAgent,s, epsilon = 0.1)\n",
    "    optimal_policy = lambda s:dummy_lifted_policy(elasticAgent,s, epsilon = 0)\n",
    "        \n",
    "    data_buffer = StandardBuffer(state_shape = env.observation_space.shape,\n",
    "                           action_shape = [len(env.action_space.sample())], # for discrete settings. \n",
    "                            batch_size=32, buffer_size=point_batch_size, device=\"cpu\")\n",
    "    data_buffer, info_explore = StandardBuffer.populate_buffer(data_buffer, env, \n",
    "                                                   policy = random_policy if epoch_i ==0 else explore_policy,\n",
    "                                                   episode_count=10, \n",
    "                                                   frame_count=int(point_batch_size/2))\n",
    "    data_buffer, info_optimal = StandardBuffer.populate_buffer(data_buffer, env, \n",
    "                                                   policy = random_policy if epoch_i ==0 else optimal_policy,\n",
    "                                                   episode_count=10, \n",
    "                                                   frame_count=int(point_batch_size/2))\n",
    "    global_buffer.append_buffer(data_buffer)\n",
    "    ######################################################################################################\n",
    "    \n",
    "    \n",
    "    ######### TT 2: Update Action Model  ###########################################################################\n",
    "    # Action Model\n",
    "    nn_action_model = NNActionModel(action_space = env.action_space,\n",
    "                                   n_actions = 5,\n",
    "                                   data_buffer = global_buffer,\n",
    "                                   nn_engine= config.actionModelArgs.nn_engine,\n",
    "                                   projection_fxn=lambda s: s, \n",
    "                                   )\n",
    "    action_model = EnsembleActionModel(env.action_space,[nn_action_model, cluster_action_model])\n",
    "    # action_model = cluster_action_model\n",
    "    config.mdpBuildArgs.n_tran_types = action_model.n_actions\n",
    "    elasticAgent.action_model = action_model\n",
    "    \n",
    "    sa_repr_model = DeltaPredictonRepr(s_multiplyer=2, \n",
    "                                   a_multiplyer=1,\n",
    "                                   buffer=global_buffer,\n",
    "                                   nn_engine=\"torch_pykeops\")\n",
    "    elasticAgent.repr_model = sa_repr_model\n",
    "    ######################################################################################################\n",
    "    \n",
    "\n",
    "    ######### TT 3: DACMDP Elastic Build   ###########################################################################\n",
    "    transitions = DACTransitionBatch(torch.FloatTensor(data_buffer.state).clone().detach(),\n",
    "                                    torch.FloatTensor(data_buffer.action).clone().detach(),\n",
    "                                    torch.FloatTensor(data_buffer.next_state).clone().detach(),\n",
    "                                    torch.FloatTensor(data_buffer.reward.reshape(-1)).clone().detach(), \n",
    "                                    torch.LongTensor((1- data_buffer.not_done).reshape(-1)).clone().detach())\n",
    "\n",
    "    st = time.time()\n",
    "    elasticAgent.consume_transitions(transitions, verbose = True, batch_size = 1000)\n",
    "    elasticAgent.dacmdp_core.solve(max_n_backups = config.mdpSolveArgs.max_n_backups, \n",
    "                                   penalty_beta = config.mdpSolveArgs.penalty_beta, \n",
    "                                   epsilon = config.mdpSolveArgs.epsilon, \n",
    "                                   gamma = config.mdpSolveArgs.gamma, \n",
    "                                   operator=\"simple_backup\", \n",
    "                                   bellman_backup_batch_size=500)\n",
    "\n",
    "    print(f\"Epoch {epoch_i}: Graph built and solved in {time.time()-st:.2f} Seconds\")\n",
    "    ######################################################################################################\n",
    "\n",
    "    \n",
    "    ######### TT 4: Eval  ###########################################################################\n",
    "    if not config.evalArgs.skip_eval:\n",
    "        st = time.time()\n",
    "        eval_policy = lambda s:dummy_lifted_policy(elasticAgent,s, epsilon = 0)\n",
    "        config.evalArgs.eval_episode_count = 100\n",
    "        avg_rewards, info = evaluate_on_env(env, eval_policy, eps_count=config.evalArgs.eval_episode_count)\n",
    "        eval_time =  time.time()-st\n",
    "        print(f\"Epoch {epoch_i}: Evaluation compltete\", avg_rewards, \"Time: \",eval_time, \"Seconds\")\n",
    "        rewards_log.append(avg_rewards)\n",
    "        \n",
    "    if not config.evalArgs.skip_dist_log:\n",
    "        image_array= plot_distributions_as_rgb_array(elasticAgent.dacmdp_core.mdp_distributions)\n",
    "        dac_plot_log.append(image_array)\n",
    "        images = wandb_logger.Image(image_array, caption=\"MDP Distributions\")\n",
    "    \n",
    "    if not config.logArgs.no_wandb_logging:   \n",
    "        wandb_logger.log({\"epoch_i\":epoch_i, \"buffer_size\":len(global_buffer), \"Average Reward\":avg_rewards,\n",
    "                         \"explore_data_collection_traj_reward\":np.mean(info_explore[\"all_rewards\"]), \n",
    "                         \"optimal_data_collection_traj_reward\":np.mean(info_optimal[\"all_rewards\"]), \n",
    "                         \"mdp_distribution\":images\n",
    "                         })\n",
    "\n",
    "    ######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a852fc45-f35c-4976-8dc5-743f5b0a5cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c11c326-c584-4d26-a64f-abb0871489bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f55becb85d0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAGdCAYAAADJ6dNTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABWzklEQVR4nO3dd3hUZfo+8HtKZlInvZJGDyGFDhFBBCRibCu2FYVdd3Vlo2v7IcuuZdVV+OLqWta2umsFsSyooEiVoBI6IaEFEgIJpJFAMmkzk8yc3x8z55A2yUySKSH357pymUw9OYaZe973eZ9XJgiCACIiIiI3IXf1ARARERG1xnBCREREboXhhIiIiNwKwwkRERG5FYYTIiIicisMJ0RERORWGE6IiIjIrTCcEBERkVtRuvoAesJkMqG0tBR+fn6QyWSuPhwiIiKygSAIqKurQ1RUFORy6+Mj/TKclJaWIiYmxtWHQURERD1QUlKC6Ohoq9f3y3Di5+cHwPzLaTQaFx8NERER2UKr1SImJkZ6H7emX4YTcSpHo9EwnBAREfUz3ZVksCCWiIiI3ArDCREREbkVhhMiIiJyKwwnRERE5FYYToiIiMitMJwQERGRW2E4ISIiIrfCcEJERERuheGEiIiI3ArDCREREbkVhhMiIiJyKwwnRERE5FYYToiIiNzQyt1nkF1Y7erDcAmGEyIiIjdztFSLv649jEc/z3H1obgEwwkREZGbOVlZBwAo1+pQ29Ts4qNxPoYTIiIiN1NU1SB9f7rV9wMFwwkREZGbaR1IihhOiIiIyNWKGE6IiIjIXQiCwHDi6gMgIiKiSy42NkOra5F+ZjghIiIilyqqqgcAKOQyy88NEATBlYfkdAwnREREbqSoqhEAMDYmADIZUK9vQVW9wcVH5VwMJ0RERG5EXKkzIsIP0YFeAAbe1A7DCRERkRsRg8jgYB8MDvG1XFbvykNyOoYTIiIiNyKFkxAfDA72BgCcGmAjJ0pXHwARERGZCYKA09XmIBIf4oOzF831JwOtSyxHToiIiNxEZZ0ejQYj5DIgNsgbg0PFaR2GEyIiInIBMYREB3pDpZRjSIgPAOB0dSOMpoGznJjhhIiIyE2I0zfxllASFeAFlUIOQ4sJpTVNrjw0p2I4ISIichOXVuqYC2EVchliLd+LtSgDAcMJERGRm2i9Ukckfj+Q6k4YToiIqF8TBAFV9XpXH0afaL1SRyTWnZw6z3BCRERks5ILjZj0whb8dW2e05976Zo8TPj7Fvz5f7loMhid/vx9xWQScLravHR4iKX5GsCRE6IBY9epapwbQMVlRI72/k+nUFmnx1f7z0LX7LyAsOtUNVbvLQEArN5bgpve/BknK+qc9vx9qbS2CYYWEzwUMkQFeEqXx0srdhhOiC5b63NLcee/d+G3H+wZcDt9EjlCbVMzvtx/FgCgbzHhUEmNU563xWjCM98cAQBcNSIUIb5qnKioxw3/+hlf7C3pd/++T1s2/IsJ8oZScentWZzWKbnQCEOLyabHev+nU3hk9UGnBsW+xHBCA4pW14zn1h0FAJyoqMfhc1oXHxFdjmqbmvHqlhM40U8/wdvri70laGw1nbLr1AWnPO/H2WeQX1GHQG8PvHbnGGx4eBquHBYCXbMJT/wvF49+noN6fYtTjqUviPvnDGlVbwIAoX5q+KgUMAlA8YXGbh9H12zEih/y8XVOKb7cV+KQY3U0hhMaUF7ZdAKVdZcK5749dM6FR0OXI6NJwIOrDuDVLSfxxFe5rj4ch2sxmvDhztMAgDExAQCA7FNVDn/e83V6/HPzCQDA4vQEBHirEOqnxsf3TsLi9JFQyGX4OqcUN7zxMw6fq3X48fSFIsvISXxw23Aik8kwONT2upP9Zy7CYDSPsLz/c1G/bN7GcEIDRu7ZGnycfRoA8Jsr4gEA6w6VwdQP/+EOJGW1TWg0OP/T7we/FGHSC1uw5WiFXfd7aWM+fjppfnPOKalB4fnLezfZzUcrcK6mCUE+Kvz95iQAwIHiGodPJ/zfD8dRp29B8iB/3DExRrpcLpch8+phWH3/FET6e6KoqgG3vLUTn+0pdujx9AVx5CS+3cgJcCmw2LLHTnZhtfT9mepGbDxS3kdH6DwMJzQgGE0C/rr2MEwCcPOYKCy9LgF+nkqUa3XYc9o5Q9Bkv8PnajF9xY+45z97nBoi9S1GvLGtAJV1evxx5QHsOHHepvutzy3FO1mFAIBBAV4AgP9ZajH6gy1HKzD2uU34Jsf2EcX//lIEAJg/ORajozQI8VXD0GJCjgPrTvafuYivLOf12ZtGQyGXdbjNxPggfP+naZg9KgwGowlL1+S5/QjKpZU6HcOJtJzYlnByqrrNfd7dcarf1d8wnNCA8En2aeSdq4WfpxJ/zUiEWqnA3KQIAMA3OaUuPjrXu9hgwHPrjqKg0r1qJN7/6RSajQL2n7mIH5z46W/TkQpcaDAAAAxGE+7/ZB92n6ru8j7Hy7VY/KV5GucP04fgrxmjAABrDpzrN8Pq//2lCBcbm/GXNXkosaG2IfdsDfaevggPhQx3T4mDTCbDlCFBAMyraBzBaBLw9DeHAQC3T4jGuNhAq7cN9FHhvQUTkJEcCcA82mKv17acxFUv/WjT+eiNZqNJeo7ORk4uTet0PRLXoG+RCpJfvj0VKqUch0rM/5/6E4YTuuxVaHX4xybz3PSSaxMQ6qcGANw0ZhAAYMPhMpsr4C9Xb2wrwH9/KcIDnx5As9E9zkWlVofv8sqkn1/elO+0N3lxCuCBq4ZiZkIYdM0m3PvhXhws7vwFvqbRgPs/3o+mZiOmDQ/BE9cmYNaoMPh7eaBcq8POQsfXYPRWTaMBu4vMo4gNBiP+vCa320/bH/xyGgCQkRyJcI156Wva0GAAjgsnn+0pxpFSLfw8lXji2oRuby+TybDk2gR4KGT46WQVfjpp2ygYYJ6We3XrCZypbpRGahzl7MUmtJgEqJVyRGg8O1w/OMS23Yn3nbmIFpOAQQFeGBsbiHnjogEA/95R2PcH7UAMJ3TZe279UdTrWzAmJgB3TYqVLp8yJBihfmrUNDbb9YJ1uTGaBKzPNY8eFVTW4yNLcaOrfbq7GM1GAcmD/BHg7YHC8w1Ye9DxBcynqxqws7AaMhlw95RYvDV/HKYOC0aDwYiF/92DI6VtpwaMJgF/Wp2D4guNiAnywut3joVCLoNaqcANqeZP7PZO7RRU1jn8k3p7245Xwmh5U/P0kOOXgmqs3G29TqNSq5P+bu69crB0+ZQh5nDiiLqTCw0GvLQxHwDw+DUjEOKrtul+scHeuHtKHABg+YbjNk0RmqeC8yDms63H7as9stfpVm3r5Z1MUw221JxUaPVo6GIFklhvIobE308bDJkM2HKsEgWV/af+ieGELmvb8yvxXW4Z5DLghV8ltflHr5DLcH2K+c1jIE/t7C6qRmWdHjLLqXl1y0lUanUuPSZ9ixGrdp8BAPzhqiF44KqhAIBXt5xw+CiX2NDrqhGhiA70hqeHAu8tmIAJcYHQ6lpwz3/2tGny9Y9N+dhx4jw8PeR49+4JCPRRSdfdOt5cqPnDkXLU6Zptev6Cynpc99rP+NVbvzi1R8VmS+HvLeMGYXG6eURi2ffHrIakT3edQbNRwIS4QKREB0iXDwnxQaifue7kYHFNnx7jSxvzUdvUjIQIPyls2OqhmcPhp1biSKkW3x7q/t/7J9mnzSM0aiVkMuDwOS3Kax3370IcEWm/Ukfk7+2BIMvfVlfN2LIto3RplpA4NNQXs0eFAzBPk/YXDCd02dI1G/G0pUHTb6cOxugo/w63uTE1CoD5hdkVK0LcwTrLC/Vt46ORGu2Pen0Llm+wf26+L32XW4aqegMiNJ5IHx2BhWnxCPVT4+zFJnzuwL4NhhYTvtpvfvxftxpl81Yp8d/fTkRKtD8uNBhw1/u7UVTVgO9yy/D2dvNw+YpbU5EYpWnzeKnR/hga6gNdswnft5qi6spLG4/DYDShqt7gtFUWumYjsixFv3MSI/DbK+IxMT4QDQYjlvwvt8NIg67ZiE8toyqtR00AWOpO+n5qJ/dsDVbvNT/nczcltWlSZosgHxUemGEOuf/YlA99i/XgV6nV4WXLVPATcxOkJdLbjlfa9ZxHSmuR8fpP+NGG+0nhpJN6E1F3bey1umbkWYp+xZETwFwDBZjrnyrrXPvBw1YMJ3TZevPHAhRfaESExhOPXjOi09uMiQlAbJA3mpqN0ifHgcTQYsL3eeY3wJvHDMJzNyVBJgPWHDyHvS5axSQIglTLcE9aHDwUcnipFHho5jAAwBtbTzps/5QtxypQVW9AmJ8aMxPC2lyn8fTAx/dOQkKEH87X6XHXe7uw+KtDAID7pw+Rgm5rMpkM88ab5/z/t7/7KakDxRex8cilv8MvnNRA65eCKjQajIj090TSIA3kchleujUVnh5y7Cysxsp2y3C/zSnFhQYDBgV4YU5ieIfHS+vjcGIyCXjqmyMQLKvtJg0O6tHj3Dt1MMI15pD7SfYZq7f7+3fHUKdvQWq0P+6aFItZlr+FbXZO7bz1YyGOlGrx8ub8bm8rjoZ0tlJHJIUTKxsA7i26AJMAxAd7I8qyWgwAJsQHYVxsAAxGEz7eaf33dicMJ3RZKqisl5Z0/u3GRPiqlZ3eTiaTSW8q62wY6r3c/HTyPGqbmhHmp8bkIcFIjQnAHRPMUxFPf3PEJatMDhRfRN65WqiU8jajF3dOjMWgAC9U1unxya7TDnlusRD29gkx8Ojkk3mAtwqf/n4yhoT6oKxWh0aDEVOHBeOJ9JFWH/OWsdGQy4A9py/gTBfD8YIg4P8sI1bTR4QCAH4pqHZK7ckmSyCakxgOmWV+Lz7EB090Mr0jCIK0fHjhFXGdjmCIK3YOlvS+7qTR0IKHVh/EoZIa+KgUWHrdqB4/lpdKgccsH1T+9WMBaps6TrX9UlCFbw+VQi4D/n5zMhRyGWYmmAPYzwVVNv8+dbpmbDlmPq+Hz2m7rfewa+TEyt9R+3qT1u63jJ58sutMlzUrAHCmugH3f7wPFy0r1lyB4YQuS8+uO4Jmo4CZCWFIHx3R5W1vGmMOJ1knzqOm0XX/GHvrh8NlWPTpfpyvs33reHHuPSMlUuoVsTh9JDSeShwr00p1H84kjprcPCZKmmMHAJVSjodnDwcAvL290OYaDlsVVzdKzdNaN/VqL8RXjVW/n4LESA0SIzX416/HdTnFEOHvianDQgAA/ztgffRk+4nz2F10ASqlHMtvScbUYeY3GEevEjGaBOlNdE67fyu/uSIek+KD0Ggw4omvzNM72YXVOF5eBy8PBe6YENvZQ2JwiA/CLHUnB6yscLLF2YuNuPXtbHyXWwalXIYXb0mWVgX11Lxx0Rge5ouaxmZpSk6kbzHiqa/Ny5TvmRKH5GjzVPCoSD9E+XtC12yyeeXVD4fLoW9VH9VVnYuu2ShtRBof4m31dt1N64j9TcRptdauSYxAfLA3apuarY7ICYKAL/eV4LrXfsKmoxV4/rujVo/F0RhO6LJTcsH8JiOTAc/ckCh9ErRmeLgfEiL80GwUsOFw/+ukKPq/H/Kx4XA5/rnlhE23bzJcmspqPSUR7KvG/7OMBLy0MR/V9baHnd4qq22S/h8stHTxbe2WsYMwJNQHFxub8d+fT/fpc3++zzxqMm14CGKCrL9BAObA8d2frsT6h65sUwBrza2WqZ01B852ulLEZBKw4gfz0P9vrohHVIAXbreMYH21v/P79JUDxRdR3WCAxlPZYbpELpdhxa0p8PSQI/tUNVbuPiONmtw6Phr+3h6dPmbbupOeTQ/uPlWNG//1C46WaRHso8Kq+6ZIy/97Q6mQY4llCfIHvxShtNXu5P/OOoVTVQ0I8VXj8VajYTKZDDNHmad2th6zre5ELLIfFWmuQ/o255zVpdklFxohCICvWonQLlYgdRVOahoNOFpm3issrZNwopDL8Ptp5tGT//xchJZ2LQNqG5vx4GcHsfirXDQYjJg0OAiPz7E+IuhoDCfUpdNVDfhsT3GHP2R3ts6yvHHK4GDEWal8b0980bOnM6Y7Ka/VSS9YX+4rwdmL3U8FbDlWgUaDEbFB3lLBn+iuSbEYFamBVteCf2zqfr68r3y66wyMJgGTBgd1WsCsVMilYfn3fjrVZ8POzUYTvthnHqFovdy8KzKZrNMln51JHx0BP7USZy82ddqR+NtDpThWZu7d8UdL0Wb66Aj4eSpxrqZJ+kTsCJssRbezRoV3OpUVH+KDP1vezF/8/ji2Woo7fzM1vsvH7U2/k092ncH893fjQoMBo6M0+PahK3tcZ9KZWaPCMCk+CPoWk7Q/T3F1I/71YwEA4KnrR0Hj2TZ4zbJM7Ww7Xtlt/5fKVr1t/nlHKrw8FDhd3Yjcs513qL00pePd5YcpcSVPTWNzh7/93UUXIAjA0FAfhFkZXbp1fDSCfFQ4e7GpzQexXaeqce1rO6QRqsXpI/HZfVOkLseuwHBCXXrqm8NYuiZPGvbtD761fGIRp2tsIfaj2F10waHLBR2l9UZrzUYBb1peZLsiDjPfkBrZ4QVRqZDjuZtGAzAvrT3kwFbkIl2zEavEFSBdvPFdlxSJUZEa1Otb8E4fNZbaeqwS5+v0CPFVY3YnBZ695emhQIZl2Xr7aRp9i1EKgA9cNRQB3irpPuLfsKMKYwVBwKajl+pNrFmQFo/Jg4PQ1GyEIABXjwzF0FDfLh9bHDnJsaPfiaHFhL+szcNTXx9Gi0nADalR+OqBK/r8TVImk2HpdebA9b8DZ5FfXodnvj0MfYsJU4cFd1rcnDY0GF4eCpTV6qQRCmvW5ZbBJADjYgOQEKHBNZZza61lQXfLiEVeKgUi/c3Bo33dSVf1JiJPDwUWpJmXYP97xykYWkxY8cNx/Pq9XSir1SE+2Bv/W3QFMq8e1umWAM7EcEJdOlqqbfNfd3e8XIvj5XVQKeSYmxRp8/2iA70xIS4QggCpsVR/Ir4wTYo3f7r8ct/ZLgspa5uakZVvXjp6Y2rnQ+UT44Pwq7GDIAjA098ecfjeNt8eKsXFxmYMCvCS+jJ0Ri6XYXG6efTko52n+6Qni1gIe9uE6E5HD/qCOLWzIa+szbL1VbuLcfZiE8L81Lh3attlueLUzobD5aht7NsaGwA4UVGPM9WNUCnlUhFuZ8TVO14eCgAdlw93Jj7YG+EaNQxG2+pOztfpMf/9XVi1uxgymbmb8+t3joGXSmH7L2SHsbGBuC45AiYB+P3He/Fj/nl4KGSWFWsd35g9PRRS7dC2bqZ2xBHYm8ea/22JIXNdbmmnRea2rNQRWVuxI45QpQ0J6fL+C9LioVbKkXeuFumv7sBb2wshCOatAL770zSkthtFdRWGE7Kqul6PasvQYaGVpWvuRhw1mTEy1Op8uDXiC4gtDZrcjTjsv2jGUEwbHoIWk4B/bbM+erLxcDkMRhNGhPtiZISf1dstnZsAH5UCh0pq8NUBxxVmtl8+3F0Pi6tHhmFcbAB0zSZpKL6nSi40YoelQ/CdXRTC9tb4uEDEB3ujwWDED5Yh9Xp9i/T/6eHZwzu8EScP8sfIcD8YWkz41gGhWZzSmTYsBD5WVrSJYoO9sfK+yXj912Mxbbj1ICNqU3dS2PXUTqOhBXe8m429py/CT63EfxdOxKIZQ7utF+utxekJUMplKLlgrjv5w/ShXY4IzbbUnWzpom/JqfP1yD1bC4VcJu3pM214KAK8PXC+Tt9mx2CRLSt1RJ3VnVTX63G83NwYUFwpZU2Qjwq3TYiWHsPfywNvzR+HFbemdvs34EwMJ2TVyVZL3/pD22NBEKRh054Uzl2XbF6xknu2ttv9K9zJ2YuNKLnQBIVchomDg/DIbPOowlcHzqK4uvPRE7Eup7Ph69bCNJ7S473w3TE89kUOXt6Uj9V7ivHTyfMoPF/fJ11M9xRdwLEyLTw95DYFBJlMJhXtfranGKfO9/zv88t9JRAE4MphITbXKPWETCbDLZZ9Tv5nCXrv7TiF6gYDBof4SKMk7e8jvpF86YCpHWlKZ7RtU1njYgO7/Ztpzdai2BU/5ONUVQMiNJ74+sGpuLpdjxlHGRziIy1XjwnywoOWXjrWiMd1qKTG6qq4ry2vQdOGhyDYUtyqUspxXbLYjbpjXVtRq9b1thxz6/sAkPZEGhnuJz1nVx64aijig71x1YhQbHh4mnRs7oThhKxqHU6Kqhrcvij2QPFFnKtpgo9KgVmj7H9xC/ZV40rLsO23ncwNtxhN2H/mAl7bchIfZ5/u0RbkgiD0+dbl4iex5EH+8FUrMT4uENNHhMJoEvDGtpMdbn++To9fCsw1KjfY8Ebzm6nxSIjwQ21TM9YcOIc3thXgz2vycM9/9mDWy1lIeOoHjH9+M+7/eB+2HK3o0d/Jh5b9fH41NlqquejOFUNDcOWwEDQbBdz85i89mo5rMZqkjrO/trEQtjduGWcOzTsLq5F7tkZqJ/7/5oy0Op30q7GDoLSE5uPlfTe9WlrThLxztZDJzMWwjiCuGskpqbHaOG/3qWrp//+KW1O6rWXpa09cOxIPXj0M7y2YAE+PrqeQwjWeSB5kLtTurOur+QOSZUqn3Qekmyz/1n44XN4m0DcaWlChNQednoYTW+pNWosO9Mb2xVfjo3sntWnW5k4YTsiqglb7hxiMJpRcbOri1q4njpqkJ0V0+yJjjfip8JtD5mV/Z6ob8MmuM7j/430Y+9xmzHs7G//ccgJPf3NE+rRijzd/LMDIJ3/o07be4pRO6xemRy39QNYcPCdtKCb6Ps9crJcaE2DTSIGHQo7/LboCr905BovTR2L+5FjMGBmK4WG+8LZMQ1Q3GLDpaAV+//E+XLF8G1b8cLzD81pzrqZJatP+m06WD3dlxa0pSI0JgFbXggdXHcRjX+TY1f/kx/zzqNDqEeyjkooWHSk60BtpQ4IhCMC9H+5Fg8GIlGh/XJdsvRdPsK9aqsH5cl/fTa2Jy8gnxAXavIGeveKCvRGh8YTBaOp0R+cmgxFP/C8XAHDHhJgu614cxc/TA/8vfSQSIjTd3xiQPvh0thHgobO1OFPdCC8PRYe/p4nxQYj090SdvgXb8y8Fm9NV5tHNAG8Pm4J563AiftDpqr9Jf+U+E0zkdk5UtB0qL6istynZu0Kz0YTvcs17l/SmF8Kc0eFQr5Xj1PkGXPl/P0qNkUQB3h4I9FahqKoBn2SfsevFQKszN30yGE14fevJPnkhEQRBms9v3dtgbGwgZowMxfb883hjWwFevj1Vuk6sqbFneN5Hrez0vAqCgNqmZpyubsR3uaWWvTv0eGt7Id7aXojJg4Nw56QYzE2KhFopR4PBiIsNBlQ3GHCxwYALDQZsOloOkwBcMTS4y/qXzkQFeOGrB9Lw+taTePPHAqw5YG67/+odYzA+rvulp2Ih7K3jo6FSOuez2rzx0cg+VY2qenM915JrE7qtrbh9YjR+OFKOtQfPYcm1CX1yrJuOmgPhnMSumxT2hrnuJAhf55Ri16lqXDGsbbHmPzbl40x1IyL9PfHX63ve+dWZZiWE49UtJ/HTySroW4xQKy99EPrasmv2nNHhHeo35HJzN+p3d5zCNzmluNZSsG/PlA4AxAR5QyGXoanZiAqtHnK5+bVZJuu+3qQ/YTghq8Rpnfhgb5yubkTh+XpcA8d/uuyJXwqqUN1gQLCPClNtHNrsjJ+nB2YnhuO73DKcq2mCUi6TpkmmDQ/B6Ch/nKiow9zXfsIPR8pRXqtDhL9tHSu/3HcWDZah7Z2F1ThWppUaNPVU8YVGlNbq4KGQYUJ8YJvrHpk9Atvzz2PtwbN4cOYwDA7xwdmLjdh/5iJkMkg7MveGTCZDgLcKY7xVGBMTgMXpCdh6rAKf7yvBDkvH091FF/Dn/5m3njd0MeVj76iJyEMhx+NzRmL6iFA8+nkOSi404bZ3svHg1cPw0KzhbaZLBEHA2YtNyCmpQU5JjfQJtquOsH1tblIEnv7mMBoNRkwbHiKtAOnK9OGhCPNTo7JOj23HK6Q3tp6qbWyW6kAcPWI0ZUgwvs4p7dCrZd/pC1JDtxdvSe7QV8RdjY7SSP8vdp26gKssoz0tRpM0tdh+Skd04xhzONl6vBJaXTM0nh7SSp3BNtY7eSjkiA3yRlFVA05V1Ushd1SExuYp0f6A4YQ6dbHBgCpLZ9D0pAi8m3XKrYtixRqR61Mi7d6ttL1nrk9EYqQGCRF+mDwkuMO+PKMiNZg0OAh7ii5g1e4zeMyGLopGk4CPLPPqgd4euNjYjA9+KcKKW1O7vmM3xOmh1OgAeKvaHueYmADMTAjDtuOVeGPrSbxyxxisO2QeXZoyOLjXbcA7o1LKMTc5EnOTI1Fa04Sv9p/FF/tKcLbVlKCXhwJBPioE+phHoYJ8VBgVqen1m+TE+CB8//A0/O3bI1hz4Bxe31aAHSersGjGUJwor0NOSQ0Ona2RXsxF04aHYIgT6xx81Er8YfpQrN5bjL9m2DZaoFTIccu4aLyTVYgv9p3tdTjZll8Bo0nAyHA/m1aI9IY43SjWnXipFNA1m9vhC4J51Orqkc4pgO0LcrkMs0aF4bM9Jdh2rEIKJ78UmkfDgnxUuHJ454EzMVKDYWG+KKisx8bD5bhtQoxdK3VE8cHmcHK6qhF552oA2F5v0l8wnPQTOwuqMCzcF2F+ff+G0hlx1GRQgBdSBgUAcN8VO00Go1SzcGMftLcO03gi8+quq/YXpMWZw8meEjw4c3i3w+zbjlei+EIj/L088K+7xmH++7vxdU4pnrg2oVfz/d0Vwj0yezi2Ha/E1znnkDlz2KUpHTsa1PVUVIAX/jRrOB68ehhOVTXAW6VAoLfKYX0rAPPOwa/cPgYzE8LwlzV5yCmpwR8+2d/mNh4KGUZFajAmJgCp0QEOabrWnYdnD5f2CbLVbRPM4WR7fiUqtLpOw6XJJGBnYTWq6vWYMzq8Q2AVbbZzlU5vxAZ5I9LfE2W1Ohwovoipw0LwyuYTOFXVgDA/NZ7KSHT4MfS1mQnh+GxPCbYcq8TfbhQgk8nwjWVKJyM50mpxs0wmw02pUXh58wl8e6i0TTixZ8p8cIgvfsw/j6Kq+kuvAZdRvQnAcNIv7Cyowl3v78a04SH45HeTnfKcJyvNxbDDw30xLMz8qbKwsh6CIDi894C9thyrQIPBiOhAL4yLDXDKc6aPjpCGdjccLuu2zuUDy/D1nZNicMVQ8+6/h0pqsHJXsd1vUiJBEC4Vw1p5YUqJDsDsUWHYcqwST3yVi2NlWijlMsxNclydQXtyuUz6G3KW61OiMC42EH/79ggKztcjKcrfHEZiAjA6StPjgmlXGhrqiwlxgdh35iLWHDiHRZY294B5pPPL/SVYtbsYpy3Lx0N8VVg0YxjmT45t8/vqmo3YbmnA58h6E5HY72TtwXPYdaoaXiqFtErpxV8l292PyB1MHRYMlVKOczVNOFFRj9ggb+kD0s1juw7+N44xh5NfCqpQWaeTCsftCieh5tvuLKzG6epGyGXApMuo3gTgap1+QXwD2l10AfqW3veUsMVJSzHsiHA/xId4Qy4D6vQtdu146yzftGpX76zg5KGQY/5kcxvoj7O73rn3eLkWOwuroZDLsCAtHjKZTGrP/smuMz3+f1pU1YAKrR4qhRzj4gKt3k7sU7L/jHm1xPQRoZfV3LQ1UQFe+PeCCdj2+Ay8/uuxuPfKwRgfF9gvg4lI7IVi7s0i4EDxRTz2RQ4mL9uKF78/jtPVjfBTKzEowAtV9QY8v/4oZry0HZ/sOgODZYfcnYVVaDQYEenviaRBvat5spVYqLnjxHks/vIQTIJ5ibQrRq36grdKKdW2bT1eIX1AignywrhY6/8WASAu2AdjYgJgEoDPdpdIjS7tmdYRO8kesXTuThrk329qdmzFcNIP5J0zbxZlaDFJf4yOJo6cDAvzhVqpQKxll1Z3m9qpaTQg64S5qLEvdiy1x68nx8BDIcP+Mxdx+FznG3oBwIeWzqfpo8OlPUKuS45EuEaNqno91lvqQOwlhtaxsQFdvuEmDfJvU89hzyodci/XpUTCy0OBU1UNmPVyFm55ayfWHDgHQ4sJo6M0WH5LMnb/dRa2L56BZbckI8rfE+VaHZ76+jBmvrwdX+wrwfd54iqdcKeFebGl+qGztSg8b97195kb+t90TmszLcu7tx6rlHqb3JQ6yKZzerNlWvU/P5tHkEL91B1q27rSPshcblM6QC/DyfLlyyGTyfDII49Il82YMQMymazN1wMPPNDmfsXFxcjIyIC3tzfCwsKwePFitLS0gDoSBKHNG9+BM93vUdEXxJGT4ZbheHFYvqAXnTgdYcPhcjQbBSRE+GFEuH3LUHsrzM9TKkz8xMroyYUGA9Za5qJ/22rfFA+FHAvS4gEA//2lqEeN2expvPTI7OGQycxbsjujnwc5hq9aKW0geKqqASqlHPPGRWPtH6/A+oeuxJ2TYuGtUsJDIcevJ8Xix8Uz8OyNoxHqp8bZi0144qtcaePBOaOdN7UXE+SFqFar2l74VVK/H72bZekWe6D4ojRNZutmoxkpUZDLAK3O/L5n60odUaTGE+pWdW6XWzEs0ItwsnfvXrz77rtISUnpcN19992HsrIy6WvFihXSdUajERkZGTAYDNi5cyc++ugjfPjhh3j66ad7eiiXtXKtrs3qgv1OCCe1jc2otEzfDLe84Q8Vw4mbjZxIn1icPGoiWmjZ4fPrnHOoaTR0uP6zPcXQt5iQNEiDCe2mXu6aFAu1Uo4jpVrssbOhmyAI0lJQWz41jY7yx+f3p2H1/VPcav8Mst9j14zADalR+Ot1o7B76Sy8fHsqxsYGdvqJXa1UYOEV8dix+Gr89bpRCPIxB4JAbw9MGuy8GgWZTCatYLkxNQrpTgxGjhIV4IVRkRoIAtBiEpAYqZFeL7sT6qdus4Q8PsTbrueWy2VSjYpSLsPE+Mur3gToYTipr6/H/Pnz8d577yEwsOP8mre3NyIiIqQvjebSvOamTZtw9OhRfPrppxgzZgzmzp2L559/Hm+++SYMho4v7gNd7lnzqInKUv2978zFPm9/3p44pRPl7ykNNQ4Ldb9wUlbbJHVpdcbqk86MjwtEYqQG+hZTh+6dzUaTNKLy2ysGd3jzCPRRSXutiP0ebFVQWY+qej3USjnG2FgEPGlwEJIsrbep/4oK8MIbvx6L+6YPQaCPbaMPXioF7ps+BDueuBrLbknGf38z0WG7L1vzxLUJWH5LMv5vXscPtP3VrFZ7AHVXCNte6w9Ug0PsLxgXw0lKtP9l+YGjR3+dmZmZyMjIwOzZszu9fuXKlQgJCUFSUhKWLl2KxsZLm49lZ2cjOTkZ4eGXhpbT09Oh1Wpx5MiRTh9Pr9dDq9W2+RooxCmd9KQIKOUynK/Tt+kZ4QjiMuJhrT4FSCt23GhaZ/2hMggCMCk+SKrlcDaZTIaFV5hHTz7ZdabNdugbDpejXKtDiK8a16d23pdCLIzddLTC6iZ9nRHrTSbEB7bpUEnUFV+1Er+eFIux3RRtOkKIrxp3Top16FJyZxNb2ctkwI2p9o3epo8Ol1oQDLZz5AQwfzACnDs950x2x63Vq1fjwIED2Lt3b6fX33XXXYiLi0NUVBRyc3OxZMkS5OfnY82aNQCA8vLyNsEEgPRzeXl5p4+5bNkyPPvss/Ye6mVBLIadGB+I4guNOFRSgwPFFxETZP8fs63a15sAl6Z1KrR6qbOhq31zyDyl46pRE9GNqYPw4vfHUXyhEVknKjEzwfz3LC4fnj851mqAGB7uh2nDQ/DTySp8lH0aT11vW5Hg5drbgKg/GRMTgEdmD0ewr9rmTtEiP08PPH7NCGSdOI8rh9u/p9DCK+IxNjYAY2KcHzSdwa6Rk5KSEjz88MNYuXIlPD07/x9x//33Iz09HcnJyZg/fz4+/vhjrF27FoWFhT0+yKVLl6K2tlb6Kinp+63D3VHrYtikQf4Yb/m04+i6E3FaZ0T4pXCi8fRAmJ+5WVihG0ztFFTW4/A5c88OV2/37aVS4HbLtvYf7TRP4+SU1OBgcQ08FDLMn9L1brf3XmkulP18b4lNm9aZTILUGfZyLIQj6i9kMhkemT0C90yJ69H9/3DVUKy6b4pdK3VEHgo5xscFQSF3r75TfcWucLJ//35UVlZi3LhxUCqVUCqVyMrKwuuvvw6lUgmjsWO/hsmTzU3DCgoKAAARERGoqGi7m6P4c0RE58NTarUaGo2mzddAIBbDKuQyJEZqpGE8h4cTy8jJsLC2xV3D3Kgo9vs88/Lb6SNCpSI/V7p7ShxkMiDrxHmcrmqQRk1uSInqtqvvVcNDMSTUB/X6FmklRVfyK+pwsbEZ3ioFUqID+uLwiYjcil3hZNasWcjLy0NOTo70NWHCBMyfPx85OTlQKDoOXefk5AAAIiPNn27T0tKQl5eHyspLW0Zv3rwZGo0GiYn9e917XxOLYYeH+cLTQ4FxcQEAgGNlWjToHbP0WqtrRrlWBwAdunq603LinYVVAC7N+bpaXLCPtD/Iy5tPSDskt14+bI1cLsO9ltt9uPN0m7qVzohTOhPig5xe1EhE5Ax2vbL5+fkhKSmpzZePjw+Cg4ORlJSEwsJCPP/889i/fz9Onz6Nb7/9FgsWLMD06dOlJcdz5sxBYmIi7rnnHhw6dAgbN27Ek08+iczMTKjVPd9j5HIkTukkW1ZYRPp7YVCAF0wCcKikxiHPKY6KRGg84e/Vtq5kaKjYxr7BpscymgTsO30BjYa+DVK6ZiMOFNcAcK+ai3ssy4rXHSpFi0nAhLhAJEfbtjrmlnGD4O/lgTPVjdh2vLLL23bXsp6IqL/r049dKpUKW7ZswZw5c5CQkIDHH38c8+bNw7p166TbKBQKrF+/HgqFAmlpabj77ruxYMECPPfcc315KJcFsRi29RvcOAdP7ZysuLSnTnv2rtj5fG8Jbn0nG+mv7pBqJPpCTkkNDC0mhPmp7dqPwtGuGh6KuOBLhcq2jJqIvFXmVRQA8G5WodWW9kaTgN2WcznlMttLg4hI1OvF0du3b5e+j4mJQVZWVrf3iYuLw/fff9/bp76stS+GFY2PDcC6Q6XYX+yocCLWm1gPJ2eqG6BvMXa7hFWsCym50IQ7/70Lv50ajyfSE3q9lFAMOpOHBLvVJoRyuQz3TInD3787hih/T6TbuePrgrQ4/OfnU9h35iIyXv8Z/zcvGePj2gaQY2VaaHUt8FUrpRE1IqLLDSes3VT7YliR+GZ14MxFmLqpTegJscfJ8LCOnQ7D/NTwUythEoDTVV335KjTNWN3kTlEXJdsLnT+4JfTuO71n7D/jH3dUNvb5cYjB/ekxeGR2cPxxl3joLSzHiQqwAtvzR+PEF8VCirrces72Xjmm8Oob1VfJNabTIwPtPvxiYj6C766uan2xbCihEg/eHkooNW1OKQhmjitM6KTaR2ZTGZzG/ufT1ah2ShgSIgP3po/Hh/dOwkRGk8UVTXg1ney8eL3x6Brtn83Xl2zEQct9SZT3LDmQq1U4JHZI6SVVfa6JjEcWx67CreOj4YgAB9ln8GcV7LwY765DiWbS4iJaABgOHFT7YthRR4KOVJjzJf1dd1Jna4ZpbWdr9QRSUWx3QSjrZaizpmW9s5XjQjFxkenS2+6/95xChmv/4QcOwt7D5XUQN9iQqifWto2/HIT4K3CP25LxSe/m4ToQC+U1urw2w/24pHVB7G3SNxPJ6SbRyEi6r8YTtxUZ8WwIkf1Oyk8b16FE+qntrpjqC29TkwmAT+2CycA4O/lgX/clor3F0xAqJ8ahecbcNs7O6XRGluIm91NcbN6E0eYNjwUmx6djt9dORhyGfB1Tinq9C3QeCqRGDUwev0Q0cDEcOKGrBXDiqRw0sdFsSe6mNIR2RJODp2tQXWDAX5qJSZ0slvm7MRwbH50OibGB6LZKNjUeEwkFcM6cUdVV/JWKfHU9YlY88epGGnZ62jaiNDLtiskERHAcOKWrBXDisZa9lI4db4BFxr6bifngi6KYUViODlVVW+1IFccNZk+IlTa2Kq9AG+V1HhsfW6ZTTstm/ubmAOZO9abONKYmACse+hKvLdgAv5+U5KrD4eIyKEYTtyQtWJYUaCPCkNDzfUWB/tw9EScXrFWbwIAMYFeUCnk0DWbcK6m892R29ebWHN1Qhi8VQqcq2myqfZErDcJ8VVLv/9AolLKcU1iOALdoF0/EZEjMZy4IWvFsK05ou7kRCe7EbenVMgRb9neu7M29uW1Ohwp1UImA2aM7HqnTU8PBWaPMvcCWW9p996V3UVivUnQZV9vQkQ0kDGcuKGuimFFfR1OGvQt0kjIiHDr0zpAq06xndSdiK3Xx8YEINi3++0Irk8x77n0XW5Zt31bLvU3GVhTOkREAw3DiZtpXQxry8jJobM1aDaaev284tLgEF9Vt9MGw0KtF8VuO27eYbq7KR3RVSND4adWolyr67LAV99ilIKYOzZfIyKivsNw4mZaF8OO6qQYVjQkxBf+Xh7QNZtwrEzb6+ftqm19e9Yasemajfi5wLxb8MwE21q3q5UKXGNp877+UKnV2x0qqbXUm6ikXitERHR5YjhxM90Vw4rkchnGxQYA6H5qJ7+8DkdLuw4wJyrFZcRdT+kA1huxZZ+qhq7ZhEh/T4yK7P5xRDekRAEAvj9cDqOVqR133U+HiIj6HsOJm7FlSkdkS93Jd7lluO71n3DDv37G3tPW97QpsKEYVjQ01BcyGXCxsRnV9Xrp8m3HLq3SsSdATB0WAn8vD5yv02NPUefHKO7Tw3oTIqLLH8OJm7GlGFY0zhJODlgJJxvyyvCn1QdhNAkwmgQ8tOpgmzDRmrjh37AuepyIvFQKDArwAnBpakcQBKkYdtYo2+pNRCqlXNrBd31ux6md1vUmaaw3ISK67DGcuBFbi2FFqdEBUMhlKK3VobRdz5EfDpfjoc/MweTmMVEYEuqDcq0Oj35xqMOqmCaDESUXzbsMd9UdtjWpU6xlaie/og7naprg6SHHFUPt3/flesvUzg+Hy9HSrsA392wtdM2sNyEiGigYTtyIrcWwIh+1UqrtONBqpcumI+V4cNUBtFiCycu3j8Gbd42DWinHjhPn8XZWYZvHKTxfD0EAgnxUNi3/BS7VnYgjJ1stUzpXDA3pslbGmiuGBiPIR4XqBoO0865oV6HYsp71JkREAwHDiRuxtRi2tfGxbetOthytQKYlmNyYag4mYth57qbRAICXN+Vjd6sAcLKy+86w7Um9TiybBW6zsSusNUqFHNcmRQAA1h9q25Btl1RvwikdIqKBgOHEjdgzpSNqXXfy4/FK/HHlATQbBVyfEolXbk9ts0Hc7RNi8Kuxg2ASgIc+O4gqS/2JLZ1h22vdiO1Cg0Fqo9/TcAIA1yebG7L9cKQchhbz1I6hxdSqvwmLYYmIBgKGEzciFsOm2FAMKxJX7Bwu1eIPn+yHwWjCdckRePWOMVAq2v7vlclk+PvNSRga6oPKOj0e/TwHRpMg9TixZRmxSGzEdq6mCd/nlcEkAKMiNYiyFMr2xOQhwQjxVaO2qRm/WPql5J6tga7ZhGAflV0jO0RE1H8xnLiJ1sWwSXaMnAwK8EK4Rg2jSYDBaMK1oyPw2p1jOwQTkY9aibfmj4enhxw/nazCWz8WoMAyrWPPyEmgjwpBlk6y//25CAAwqxejJgCgkMtwXbJlasey186l/ibcT4eIaKBgOHESo0nA6aqGDitRRPYWw4pkMhmmWlbHzEkMxxt3jYWHlWAiGhnhh+dvSgIA/HPLCZy5YF6pM8zGlToicfTkVJW57mSmnUuIOyOu2tl0tBz6FiN2nRI3++OUDhHRQKF09QEMFO//dArLNhxHhMYTt0+Ixu0TYxAd6C1d35NiWNFT1ydibnIkZowM7TaYiG6bEINdpy7gfwfOAgACvD0QauNKHdHQMF/ssTR2C/JRITU6wK77d2ZCXCAiNJ4o1+qw9Vgl9p1hOCEiGmg4cuIk4p4z5VodXt9WgGkrfsSC/+7BD4fL0Gw09agYVhToo8I1ieE2BxPR8zePlqZyhoX62j1t0roGZMbI0DbFtz0ll8twnaUw9qWN+dA1mxDko7JryomIiPo3jpw4idgP5E8zh2F/8UX8UlCNHSfOY8eJ8wjxVUOlML+x21MM21veKiXeuWc8nlt3FHdPibP7/q3DySwbN/qzRUZKJP77SxGKLNNFU1hvQkQ0oDCcOEGdrhlltToAwO+mDcFjXh44U92A1XtL8OW+s9KSXsC+Yti+MDTUFx/dO6lH9x0Z7geZDPCQyzFthP1dYa0ZFxuAQQFeOGfpejt5MKd0iIgGEoYTJxAblYX5qeHv5QEAiAv2wZJrE/DYNSOw9Vglvtp/Fn6eSqT0Qd2Gs0T4e+Ktu8bB11MJjadHnz2uTCZDRkok/r3jFADWmxARDTQMJ05wssJ6B1YPS2dUsTtqfzPXUh/S125MjcK/d5xChMaT9SZERAMMw4kTiJvj8U3WdkmD/LHy95MR6qeGvA8KbYmIqP9gOHGCAksHVnY4tc/UYX1Xx0JERP0HlxI7gThyMizM9vbwREREAxXDiYPpmo0otnRgHW5nB1YiIqKBiOHEwQrP10MQzB1Ygy170RAREZF1DCcOJjZfGx5mfwdWIiKigYjhxMHEcMJiWCIiItswnDjYpXDCYlgiIiJbMJw42EmOnBAREdmF4cSBmo0mnLZsXscGbERERLZhOHGgM9UNaDEJ8FEpEOnv6erDISIi6hcYThyodTEsV+oQERHZhuHEgU5a2tYP5ZQOERGRzRhOHOjShn9cqUNERGQrhhMHOskN/4iIiOzGcOIgRpOAwvOXusMSERGRbRhOHOTcxSboW0xQKeWICfJ29eEQERH1GwwnDnKysg4AMCTEBwo5V+oQERHZiuHEQaQN/8JZDEtERGQPhhMHkdrWh7LehIiIyB4MJw5yaeSE4YSIiMgeDCcOIAhCm+6wREREZDuGEweo0OpRr2+BQi5DfLCPqw+HiIioX2E4cQBxpU5csDdUSp5iIiIie/Cd0wHEzrBsvkZERGQ/hhMHEPfUYb0JERGR/RhOHKCgghv+ERER9RTDiQNw5ISIiKjnGE76WHW9HhcaDJDJgKFswEZERGQ3hpM+JvY3GRTgBS+VwsVHQ0RE1P8wnPQxsW09V+oQERH1DMNJH2NnWCIiot5hOOlj0p46XKlDRETUIwwnfUwMJ0M5ckJERNQjDCd9SKtrRrlWB4DTOkRERD3FcNKHxFGTcI0a/l4eLj4aIiKi/onhpA+xGJaIiKj3ehVOli9fDplMhkceeUS6TKfTITMzE8HBwfD19cW8efNQUVHR5n7FxcXIyMiAt7c3wsLCsHjxYrS0tPTmUNwCi2GJiIh6r8fhZO/evXj33XeRkpLS5vJHH30U69atw5dffomsrCyUlpbilltuka43Go3IyMiAwWDAzp078dFHH+HDDz/E008/3fPfwk2wGJaIiKj3ehRO6uvrMX/+fLz33nsIDAyULq+trcV//vMfvPLKK5g5cybGjx+PDz74ADt37sSuXbsAAJs2bcLRo0fx6aefYsyYMZg7dy6ef/55vPnmmzAYDH3zW7nIyco6AGzARkRE1Bs9CieZmZnIyMjA7Nmz21y+f/9+NDc3t7k8ISEBsbGxyM7OBgBkZ2cjOTkZ4eHh0m3S09Oh1Wpx5MiRTp9Pr9dDq9W2+XI3TQYjzl5sAsCaEyIiot5Q2nuH1atX48CBA9i7d2+H68rLy6FSqRAQENDm8vDwcJSXl0u3aR1MxOvF6zqzbNkyPPvss/YeqlMdKL4IQQACvT0Q7KNy9eEQERH1W3aNnJSUlODhhx/GypUr4enp6ahj6mDp0qWora2VvkpKSpz23LZo0LfgL2vzAACzR4VDJpO5+IiIiIj6L7vCyf79+1FZWYlx48ZBqVRCqVQiKysLr7/+OpRKJcLDw2EwGFBTU9PmfhUVFYiIiAAAREREdFi9I/4s3qY9tVoNjUbT5sudPLvuCM5UNyLK3xNPXp/o6sMhIiLq1+wKJ7NmzUJeXh5ycnKkrwkTJmD+/PnS9x4eHti6dat0n/z8fBQXFyMtLQ0AkJaWhry8PFRWVkq32bx5MzQaDRIT+98b+4a8Mnyx7yxkMuCVO8aw+RoREVEv2VVz4ufnh6SkpDaX+fj4IDg4WLr8d7/7HR577DEEBQVBo9HgoYceQlpaGqZMmQIAmDNnDhITE3HPPfdgxYoVKC8vx5NPPonMzEyo1eo++rWco6y2CX9eY57OWXTVUEwZEuziIyIiIur/7C6I7c4///lPyOVyzJs3D3q9Hunp6Xjrrbek6xUKBdavX49FixYhLS0NPj4+WLhwIZ577rm+PhSHMpkEPP7FIdQ2NSMl2h+PzB7h6kMiIiK6LMgEQRBcfRD20mq18Pf3R21trcvqT/69oxAvfn8cXh4KfPenKzEklMuHiYiIumLr+zf31umBI6W1eGljPgDg6RsSGUyIiIj6EMOJnZoMRjy8OgfNRgFzEsNx58QYVx8SERHRZYXhxE4vfn8MBZX1CPNTY/m8FPY0ISIi6mMMJ3bYeqwCn+w6AwB4+fZUBLETLBERUZ9jOLGDWGfy+ysHY9rwUBcfDRER0eWJ4cQO5+v0AIDbJrDOhIiIyFEYTuzQ1GwEAHirFC4+EiIiossXw4mNBEGQwomnB8MJERGRozCc2EjfYoLYrs6LIydEREQOw3BiI51l1AQAPJU8bURERI7Cd1kbiVM6KoUcSgVPGxERkaPwXdZGTQax3oSnjIiIyJH4TmsjceSE9SZERESOxXBiI7HmxIsrdYiIiByK4cRGTQYTAC4jJiIicjSGExtxWoeIiMg5GE5s1MRpHSIiIqdgOLGRzsBwQkRE5AwMJzbStbB1PRERkTMwnNjoUp8ThhMiIiJHYjix0aWCWJ4yIiIiR+I7rY1YEEtEROQcDCc2YkEsERGRczCc2EgcOfFknxMiIiKHYjixUVOzuUMsR06IiIgci+HERk2c1iEiInIKhhMb6di+noiIyCkYTmwk1Zxw5ISIiMihGE5sxGkdIiIi52A4sRGndYiIiJyD4cRGbMJGRETkHAwnNmLNCRERkXMwnNhIqjnhtA4REZFDMZzYwGQSoG9hEzYiIiJnYDixga7FKH3v6cFTRkRE5Eh8p7WBztK6HgA8lRw5ISIiciSGExuIxbBqpRxyuczFR0NERHR5YzixAYthiYiInIfhxAY69jghIiJyGoYTG7ABGxERkfMwnNhAnNZhAzYiIiLHYzixQRP31SEiInIahhMbsOaEiIjIeRhObMBpHSIiIudhOLEBp3WIiIich+HEBpdW6/B0ERERORrfbW2gM7DmhIiIyFkYTmwgjpx4clqHiIjI4RhObMAmbERERM7DcGKDJoN5V2KGEyIiIsdjOLGB2OeES4mJiIgcj+HEBpzWISIich6GExvoWBBLRETkNAwnNuDICRERkfMwnNigiX1OiIiInIbhxAbSxn8qni4iIiJH47utDZq4WoeIiMhpGE5swGkdIiIi52E4sYGu2dKEjat1iIiIHI7hpBstRhMMRnaIJSIichaGk27oWkzS96w5ISIicjyGk26I9SYyGaBW8nQRERE5Gt9tu6Fr1YBNJpO5+GiIiIgufwwn3WB3WCIiIueyK5y8/fbbSElJgUajgUajQVpaGjZs2CBdP2PGDMhksjZfDzzwQJvHKC4uRkZGBry9vREWFobFixejpaWlb34bBxCndVhvQkRE5BxKe24cHR2N5cuXY/jw4RAEAR999BFuuukmHDx4EKNHjwYA3HfffXjuueek+3h7e0vfG41GZGRkICIiAjt37kRZWRkWLFgADw8PvPjii330K/UtaeSEy4iJiIicwq5wcsMNN7T5+YUXXsDbb7+NXbt2SeHE29sbERERnd5/06ZNOHr0KLZs2YLw8HCMGTMGzz//PJYsWYK//e1vUKlUPfw1HOdSd1jOgBERETlDj99xjUYjVq9ejYaGBqSlpUmXr1y5EiEhIUhKSsLSpUvR2NgoXZednY3k5GSEh4dLl6Wnp0Or1eLIkSNWn0uv10Or1bb5chYdu8MSERE5lV0jJwCQl5eHtLQ06HQ6+Pr6Yu3atUhMTAQA3HXXXYiLi0NUVBRyc3OxZMkS5OfnY82aNQCA8vLyNsEEgPRzeXm51edctmwZnn32WXsPtU9wXx0iIiLnsjucjBw5Ejk5OaitrcVXX32FhQsXIisrC4mJibj//vul2yUnJyMyMhKzZs1CYWEhhg4d2uODXLp0KR577DHpZ61Wi5iYmB4/nj24WoeIiMi57J7WUalUGDZsGMaPH49ly5YhNTUVr732Wqe3nTx5MgCgoKAAABAREYGKioo2txF/tlanAgBqtVpaISR+OQv31SEiInKuXld5mkwm6PX6Tq/LyckBAERGRgIA0tLSkJeXh8rKSuk2mzdvhkajkaaG3I2OIydEREROZde0ztKlSzF37lzExsairq4Oq1atwvbt27Fx40YUFhZi1apVuO666xAcHIzc3Fw8+uijmD59OlJSUgAAc+bMQWJiIu655x6sWLEC5eXlePLJJ5GZmQm1Wu2QX7C32OeEiIjIuewKJ5WVlViwYAHKysrg7++PlJQUbNy4Eddccw1KSkqwZcsWvPrqq2hoaEBMTAzmzZuHJ598Urq/QqHA+vXrsWjRIqSlpcHHxwcLFy5s0xfF3bDPCRERkXPZFU7+85//WL0uJiYGWVlZ3T5GXFwcvv/+e3ue1qVYEEtERORc7CzWDfY5ISIici6Gk25IfU44rUNEROQUDCfd4LQOERGRczGcdKOJ0zpEREROxXDSDanPiYqnioiIyBn4jtsN7q1DRETkXAwn3WA4ISIici6Gk240GSx76zCcEBEROQXDSTe4tw4REZFzMZx0QRAEtq8nIiJyMoaTLjQbBRhNAgDWnBARETkLw0kXxFETgNM6REREzsJw0gW9JZwo5DJ4KGQuPhoiIqKBgeGkC61b18tkDCdERETOwHDSBfY4ISIicj6Gky5I++qwdT0REZHT8F23C9yRmIiIyPkYTrrABmxERETOx3DSBbF1PWtOiIiInIfhpAvsDktEROR8DCddYM0JERGR8zGcdEFnYDghIiJyNoaTLogjJ2qGEyIiIqdhOOkCp3WIiIicj+GkC2zCRkRE5Hx81+0C+5wQERE5H8NJF7i3DhERkfMxnHTh0rQOwwkREZGzMJx0gQWxREREzsdw0gV9s7l9PcMJERGR8zCcdEGqOeG0DhERkdMwnHSB0zpERETOx3DShSa2ryciInI6hpMu6LgrMRERkdMxnHSB0zpERETOx3BihSAIbMJGRETkAgwnVuhbTBAE8/ec1iEiInIehhMrxHoTAPBU8jQRERE5C991rRCndDwUMigVPE1ERETOwnddK8RlxKw3ISIici6GEyu4UoeIiMg1GE6sYI8TIiIi12A4saLJwE3/iIiIXIHhxAr2OCEiInINhhMrWHNCRETkGgwnVugMrDkhIiJyBYYTK3QtHDkhIiJyBYYTK9jnhIiIyDUYTqyQak5UPEVERETOxHdeK1gQS0RE5BoMJ1ZIBbEMJ0RERE7FcGKF1OeEq3WIiIiciuHEiqZmdoglIiJyBYYTK5o4rUNEROQSDCdW6Ni+noiIyCUYTqzg3jpERESuwXBiRRPb1xMREbkEw4kVOvY5ISIicgmGEyvYhI2IiMg1GE6sYPt6IiIi1+A7rxXc+I+IiMg1GE46YTIJ0LewCRsREZErMJx0QtdilL7nah0iIiLnsiucvP3220hJSYFGo4FGo0FaWho2bNggXa/T6ZCZmYng4GD4+vpi3rx5qKioaPMYxcXFyMjIgLe3N8LCwrB48WK0tLT0zW/TR3SW1vUA4KlkOCEiInImu8JJdHQ0li9fjv3792Pfvn2YOXMmbrrpJhw5cgQA8Oijj2LdunX48ssvkZWVhdLSUtxyyy3S/Y1GIzIyMmAwGLBz50589NFH+PDDD/H000/37W/VS2IxrFoph1wuc/HREBERDSwyQRCE3jxAUFAQXnrpJdx6660IDQ3FqlWrcOuttwIAjh8/jlGjRiE7OxtTpkzBhg0bcP3116O0tBTh4eEAgHfeeQdLlizB+fPnoVKpbHpOrVYLf39/1NbWQqPR9ObwO1VQWY/Zr2QhwNsDOU/P6fPHJyIiGohsff/ucc2J0WjE6tWr0dDQgLS0NOzfvx/Nzc2YPXu2dJuEhATExsYiOzsbAJCdnY3k5GQpmABAeno6tFqtNPriDtiAjYiIyHWU9t4hLy8PaWlp0Ol08PX1xdq1a5GYmIicnByoVCoEBAS0uX14eDjKy8sBAOXl5W2CiXi9eJ01er0eer1e+lmr1dp72HZhAzYiIiLXsXvkZOTIkcjJycHu3buxaNEiLFy4EEePHnXEsUmWLVsGf39/6SsmJsahz8ceJ0RERK5jdzhRqVQYNmwYxo8fj2XLliE1NRWvvfYaIiIiYDAYUFNT0+b2FRUViIiIAABERER0WL0j/izepjNLly5FbW2t9FVSUmLvYdvlUndYhhMiIiJn63WfE5PJBL1ej/Hjx8PDwwNbt26VrsvPz0dxcTHS0tIAAGlpacjLy0NlZaV0m82bN0Oj0SAxMdHqc6jVamn5svjlSGLNiacH28AQERE5m101J0uXLsXcuXMRGxuLuro6rFq1Ctu3b8fGjRvh7++P3/3ud3jssccQFBQEjUaDhx56CGlpaZgyZQoAYM6cOUhMTMQ999yDFStWoLy8HE8++SQyMzOhVqsd8gv2hDitw5oTIiIi57MrnFRWVmLBggUoKyuDv78/UlJSsHHjRlxzzTUAgH/+85+Qy+WYN28e9Ho90tPT8dZbb0n3VygUWL9+PRYtWoS0tDT4+Phg4cKFeO655/r2t+qlpmbWnBAREblKr/ucuIKj+5y8tb0AK37Ix23jo/HSbal9/vhEREQDkcP7nFzOdAYWxBIREbkKw0kn2OeEiIjIdRhOOsGaEyIiItdhOOlEk8G8KzGndYiIiJyP4aQT3FuHiIjIdRhOOsGaEyIiItdhOOmE1CGW0zpEREROx3DSCY6cEBERuQ7DSSfYvp6IiMh1GE46IRXEqnh6iIiInI3vvp1gnxMiIiLXYTjpBKd1iIiIXIfhpBO6ZnMTNo6cEBEROR/DSTstRhMMRkuHWIYTIiIip2M4aUfXYpK+Z/t6IiIi52M4aUesNwEAtZKnh4iIyNn47ttO6311ZDKZi4+GiIho4GE4aUfqDsspHSIiIpdgOGmHy4iJiIhci+GknUsN2HhqiIiIXIHvwO1wWoeIiMi1GE7a0XFah4iIyKUYTtrhvjpERESuxXDSTlMzR06IiIhcieGkHXFfHdacEBERuQbDSTs6jpwQERG5FMNJO2KfE9acEBERuQbDSTtcSkxERORaDCftSKt1lAwnRERErsBw0o7U50TFU0NEROQKfAduh0uJiYiIXIvhpB02YSMiInIthpN2pF2JWRBLRETkEgwn7bDPCRERkWsxnLTDmhMiIiLXYjhpR6o54bQOERGRSzCctNNksOytw5ETIiIil2A4aYc1J0RERK7FcNKKIAhsX09ERORiDCetNBsFGE0CAPY5ISIichWGk1bEUROA0zpERESuwnDSit4SThRyGTwUMhcfDRER0cDEcNJK6x4nMhnDCRERkSswnLTCfXWIiIhcj+GkFXFfHU8PnhYiIiJX4btwK2xdT0RE5HoMJ63o2OOEiIjI5RhOWhFb17PmhIiIyHUYTlrhtA4REZHrMZy0wnBCRETkegwnregMrDkhIiJyNYaTVtjnhIiIyPUYTlrhtA4REZHrKV19AO4kbUgwFDIZxsUFuPpQiIiIBiyGk1amjwjF9BGhrj4MIiKiAY3TOkRERORWGE6IiIjIrTCcEBERkVthOCEiIiK3wnBCREREboXhhIiIiNwKwwkRERG5FYYTIiIicisMJ0RERORW7Aony5Ytw8SJE+Hn54ewsDDcfPPNyM/Pb3ObGTNmQCaTtfl64IEH2tymuLgYGRkZ8Pb2RlhYGBYvXoyWlpbe/zZERETU79nVvj4rKwuZmZmYOHEiWlpa8Je//AVz5szB0aNH4ePjI93uvvvuw3PPPSf97O3tLX1vNBqRkZGBiIgI7Ny5E2VlZViwYAE8PDzw4osv9sGvRERERP2ZTBAEoad3Pn/+PMLCwpCVlYXp06cDMI+cjBkzBq+++mqn99mwYQOuv/56lJaWIjw8HADwzjvvYMmSJTh//jxUKlW3z6vVauHv74/a2lpoNJqeHj4RERE5ka3v372qOamtrQUABAUFtbl85cqVCAkJQVJSEpYuXYrGxkbpuuzsbCQnJ0vBBADS09Oh1Wpx5MiR3hwOERERXQZ6vCuxyWTCI488gqlTpyIpKUm6/K677kJcXByioqKQm5uLJUuWID8/H2vWrAEAlJeXtwkmAKSfy8vLO30uvV4PvV4v/SyGIq1W29PDJyIiIicT37e7m7TpcTjJzMzE4cOH8fPPP7e5/P7775e+T05ORmRkJGbNmoXCwkIMHTq0R8+1bNkyPPvssx0uj4mJ6dHjERERkevU1dXB39/f6vU9CicPPvgg1q9fjx07diA6OrrL206ePBkAUFBQgKFDhyIiIgJ79uxpc5uKigoAQERERKePsXTpUjz22GPSzyaTCRcuXEBwcDBkMllPfgWrtFotYmJiUFJSwnoWG/B82Yfny348Z/bh+bIfz5l9enO+BEFAXV0doqKiurydXeFEEAQ89NBDWLt2LbZv347Bgwd3e5+cnBwAQGRkJAAgLS0NL7zwAiorKxEWFgYA2Lx5MzQaDRITEzt9DLVaDbVa3eaygIAAew7dbhqNhn+kduD5sg/Pl/14zuzD82U/njP79PR8dTViIrIrnGRmZmLVqlX45ptv4OfnJ9WI+Pv7w8vLC4WFhVi1ahWuu+46BAcHIzc3F48++iimT5+OlJQUAMCcOXOQmJiIe+65BytWrEB5eTmefPJJZGZmdgggRERENPDYtVrn7bffRm1tLWbMmIHIyEjp6/PPPwcAqFQqbNmyBXPmzEFCQgIef/xxzJs3D+vWrZMeQ6FQYP369VAoFEhLS8Pdd9+NBQsWtOmLQkRERAOX3dM6XYmJiUFWVla3jxMXF4fvv//enqd2GrVajWeeeYajODbi+bIPz5f9eM7sw/NlP54z+zjjfPWqCRsRERFRX+PGf0RERORWGE6IiIjIrTCcEBERkVthOCEiIiK3wnDSyptvvon4+Hh4enpi8uTJHTrZDmQ7duzADTfcgKioKMhkMnz99ddtrhcEAU8//TQiIyPh5eWF2bNn4+TJk645WDewbNkyTJw4EX5+fggLC8PNN9+M/Pz8NrfR6XTIzMxEcHAwfH19MW/ePKlb8kDz9ttvIyUlRWrqlJaWhg0bNkjX81x1bfny5ZDJZHjkkUeky3jO2vrb3/4GmUzW5ishIUG6nuero3PnzuHuu+9GcHAwvLy8kJycjH379knXO/J1n+HE4vPPP8djjz2GZ555BgcOHEBqairS09NRWVnp6kNzCw0NDUhNTcWbb77Z6fUrVqzA66+/jnfeeQe7d++Gj48P0tPTodPpnHyk7iErKwuZmZnYtWsXNm/ejObmZsyZMwcNDQ3SbR599FGsW7cOX375JbKyslBaWopbbrnFhUftOtHR0Vi+fDn279+Pffv2YebMmbjpppukncp5rqzbu3cv3n33XanRpYjnrKPRo0ejrKxM+mq9NxzPV1sXL17E1KlT4eHhgQ0bNuDo0aN4+eWXERgYKN3Goa/7AgmCIAiTJk0SMjMzpZ+NRqMQFRUlLFu2zIVH5Z4ACGvXrpV+NplMQkREhPDSSy9Jl9XU1AhqtVr47LPPXHCE7qeyslIAIGRlZQmCYD4/Hh4ewpdffind5tixYwIAITs721WH6VYCAwOF999/n+eqC3V1dcLw4cOFzZs3C1dddZXw8MMPC4LAv6/OPPPMM0Jqamqn1/F8dbRkyRLhyiuvtHq9o1/3OXICwGAwYP/+/Zg9e7Z0mVwux+zZs5Gdne3CI+sfioqKUF5e3ub8+fv7Y/LkyTx/FrW1tQCAoKAgAMD+/fvR3Nzc5pwlJCQgNjZ2wJ8zo9GI1atXo6GhAWlpaTxXXcjMzERGRkabcwPw78uakydPIioqCkOGDMH8+fNRXFwMgOerM99++y0mTJiA2267DWFhYRg7dizee+896XpHv+4znACoqqqC0WhEeHh4m8vDw8Ol/YPIOvEc8fx1zmQy4ZFHHsHUqVORlJQEwHzOVCpVhw0sB/I5y8vLg6+vL9RqNR544AGsXbsWiYmJPFdWrF69GgcOHMCyZcs6XMdz1tHkyZPx4Ycf4ocffsDbb7+NoqIiTJs2DXV1dTxfnTh16hTefvttDB8+HBs3bsSiRYvwpz/9CR999BEAx7/u29W+nojsl5mZicOHD7eZ36aORo4ciZycHNTW1uKrr77CwoULbdoOYyAqKSnBww8/jM2bN8PT09PVh9MvzJ07V/o+JSUFkydPRlxcHL744gt4eXm58Mjck8lkwoQJE/Diiy8CAMaOHYvDhw/jnXfewcKFCx3+/Bw5ARASEgKFQtGhMruiogIREREuOqr+QzxHPH8dPfjgg1i/fj1+/PFHREdHS5dHRETAYDCgpqamze0H8jlTqVQYNmwYxo8fj2XLliE1NRWvvfYaz1Un9u/fj8rKSowbNw5KpRJKpRJZWVl4/fXXoVQqER4eznPWjYCAAIwYMQIFBQX8G+tEZGQkEhMT21w2atQoaSrM0a/7DCcwvyiOHz8eW7dulS4zmUzYunUr0tLSXHhk/cPgwYMRERHR5vxptVrs3r17wJ4/QRDw4IMPYu3atdi2bRsGDx7c5vrx48fDw8OjzTnLz89HcXHxgD1n7ZlMJuj1ep6rTsyaNQt5eXnIycmRviZMmID58+dL3/Ocda2+vh6FhYWIjIzk31gnpk6d2qH9wYkTJxAXFwfACa/7vS6pvUysXr1aUKvVwocffigcPXpUuP/++4WAgAChvLzc1YfmFurq6oSDBw8KBw8eFAAIr7zyinDw4EHhzJkzgiAIwvLly4WAgADhm2++EXJzc4WbbrpJGDx4sNDU1OTiI3eNRYsWCf7+/sL27duFsrIy6auxsVG6zQMPPCDExsYK27ZtE/bt2yekpaUJaWlpLjxq1/nzn/8sZGVlCUVFRUJubq7w5z//WZDJZMKmTZsEQeC5skXr1TqCwHPW3uOPPy5s375dKCoqEn755Rdh9uzZQkhIiFBZWSkIAs9Xe3v27BGUSqXwwgsvCCdPnhRWrlwpeHt7C59++ql0G0e+7jOctPLGG28IsbGxgkqlEiZNmiTs2rXL1YfkNn788UcBQIevhQsXCoJgXlb21FNPCeHh4YJarRZmzZol5Ofnu/agXaizcwVA+OCDD6TbNDU1CX/84x+FwMBAwdvbW/jVr34llJWVue6gXejee+8V4uLiBJVKJYSGhgqzZs2Sgokg8FzZon044Tlr64477hAiIyMFlUolDBo0SLjjjjuEgoIC6Xqer47WrVsnJCUlCWq1WkhISBD+/e9/t7neka/7MkEQhN6PvxARERH1DdacEBERkVthOCEiIiK3wnBCREREboXhhIiIiNwKwwkRERG5FYYTIiIicisMJ0RERORWGE6IiIjIrTCcEBERkVthOCEiIiK3wnBCREREboXhhIiIiNzK/wdzHsFaNdGKfAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.plot(rewards_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "403dd03a-327a-4e25-a91b-55f74528215b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422967"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(global_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5ba50a-f532-487a-9369-311ccc5375b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
